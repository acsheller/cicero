{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49d0a1a-f8a3-4816-802e-4580a1673cd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NRMS Model\n",
    "\n",
    "NRMS stands for `Neural News Reccomendaiton with Multi-head Self-Attention`.  The reference to the paper is provided below. \n",
    "\n",
    "---\n",
    "\n",
    "## Understand the MIND dataset\n",
    "The MIND dataset consists of several key files:\n",
    "\n",
    "- news.tsv: Contains news articles and their metadata (news ID, category, subcategory, title, abstract, etc.).\n",
    "- behaviors.tsv: Contains user interaction data, including the history of news articles clicked and the impressions list (clicked or not clicked).\n",
    "\n",
    "The NRMS model uses this data to learn user preferences based on click history.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting setup\n",
    "Create the virtural environment\n",
    "```bash\n",
    "\n",
    "python -m venv nrms\n",
    "\n",
    "```\n",
    "\n",
    "Edit your .bashrc and add an alias:\n",
    "\n",
    "```.bash\n",
    "\n",
    "alias nrms='source ~/nrms/bin/activate'\n",
    "\n",
    "```\n",
    "\n",
    "Source the .bashrc file and activate the nrms enviroment'\n",
    "\n",
    "```.bash\n",
    "\n",
    "source .bashrc\n",
    "\n",
    "nrms\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Install the Python Modules Needed\n",
    "\n",
    "Note, the original NRMS was done with TENSORFLOW !!!\n",
    "```.bash\n",
    "\n",
    "\n",
    "pip install tensorflow[and-cuda]\n",
    "\n",
    "pip install jupyterlab\n",
    "\n",
    "# Start Jupyter lab at this point if you want.\n",
    "\n",
    "pip install recommenders # The Microsoft Python Module with all the recommender models in it.\n",
    "\n",
    "# We will need word embeddings\n",
    "wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "unzip glove.6B.zip\n",
    "\n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed8aee-0daa-442f-8b06-f244e871f4e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# NRMS Sequence of Steps\n",
    "\n",
    "\n",
    "## Do the imports and ensure it works\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5238d5c-9957-45d8-9028-16519f4ab63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 5.06 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Remove warnings\n",
    "import os\n",
    "os.environ['TF_TRT_ALLOW_ENGINE_NATIVE_SEGMENT_EXECUTION'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()  # Disable eager execution to use TF1.x style\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load news dataset\n",
    "dataset_path = '~/datasets/MINDsmall/train/'\n",
    "df_news = pd.read_csv(f\"{dataset_path}news.tsv\", sep=\"\\t\", names=[\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"entity\"])\n",
    "\n",
    "# Drop rows where title or abstract is NaN\n",
    "df_news.dropna(subset=['title', 'abstract'], inplace=True)\n",
    "\n",
    "# Combine all titles and abstracts to create the vocabulary\n",
    "all_texts = df_news['title'].tolist() + df_news['abstract'].tolist()\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer(num_words=50000)  # Limit vocabulary to 50000 words\n",
    "tokenizer.fit_on_texts(all_texts)\n",
    "\n",
    "# Save the word index dictionary to a file\n",
    "word_dict = tokenizer.word_index\n",
    "with open(\"word_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d4cd28-38c9-44f6-8c65-54f1f6aecb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.94 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Load behaviors dataset\n",
    "df_behaviors = pd.read_csv(f\"{dataset_path}behaviors.tsv\", sep=\"\\t\", names=[\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"])\n",
    "# Replace NaN values in history with an empty string\n",
    "df_behaviors['history'] = df_behaviors['history'].fillna(\"\")\n",
    "\n",
    "# Generate a dictionary of user IDs and their indices\n",
    "user_ids = df_behaviors['user_id'].unique()\n",
    "user_dict = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "\n",
    "# Save the user index dictionary as a pickle file\n",
    "with open(\"user_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_dict, f)\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da513a4b-6c55-4b5a-9536-ba045a7d5012",
   "metadata": {},
   "source": [
    "## Set Hyperparameters\n",
    "\n",
    "Note, this can be very different from what you read online in articles.  So be ready to dig deep to get it write. In some case new things are needed, such as userDict and wordDict -- but the abstracting away of these details by the recommender module is good, there is still some preprocessing to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927bda0a-22c7-42d9-8911-fe5eb1c1d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "\n",
    "# Prepare hyperparameters for NRMS\n",
    "hparams = prepare_hparams(\n",
    "    yaml_file=None,\n",
    "    model_type=\"nrms\",                   # Specify model type\n",
    "    data_format=\"news\",                  # Data format for NRMS (should be 'news')\n",
    "    title_size=30,                       # Maximum number of words in the title\n",
    "    word_emb_dim=300,                    # Word embedding dimension (consistent with GloVe)\n",
    "    word_size=50000,                     # Vocabulary size to use\n",
    "    dropout=0.2,                         # Dropout rate for regularization\n",
    "    epochs=10,                           # Number of epochs to train\n",
    "    batch_size=64,                       # Batch size for training\n",
    "    learning_rate=0.001,                 # Learning rate for optimization\n",
    "    npratio=4,                           # Negative sampling ratio\n",
    "    his_size=50,                         # Number of historical news articles to consider\n",
    "    head_num=8,                          # Number of attention heads in the multi-head attention mechanism\n",
    "    head_dim=64,                         # Dimension size of each attention head\n",
    "    attention_hidden_dim=200,            # Hidden dimension size for the attention mechanism\n",
    "    loss=\"cross_entropy\",                # Loss function to be used during training\n",
    "    userDict_file=\"user_dict.pkl\",       # Path to the generated user dictionary file\n",
    "    wordDict_file=\"word_dict.pkl\",       # Path to the generated word dictionary file\n",
    "    wordEmb_file=\"glove.6B.300d.txt\"     # Path to pre-trained GloVe embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38992d3c-48ff-42f6-83d9-97df56979ae4",
   "metadata": {},
   "source": [
    "## The next step would be to initialize your data iterators and train the NRMS model. Here’s a summary of what’s next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6507fab-a26f-4430-80c3-ed7cc9a277d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "\n",
    "# Initialize MIND data iterator\n",
    "iterator = MINDIterator(hparams)\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_data = iterator.load_data_from_file(f\"{dataset_path}behaviors.tsv\", f\"{dataset_path}news.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e17bad1-e318-4d09-8ff9-5bba852be4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m iterator_creator \u001b[38;5;241m=\u001b[39m MINDIterator\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Initialize the NRMS model with both hparams and iterator_creator\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNRMSModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nrms_tf/lib/python3.10/site-packages/recommenders/models/newsrec/models/nrms.py:42\u001b[0m, in \u001b[0;36mNRMSModel.__init__\u001b[0;34m(self, hparams, iterator_creator, seed)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     29\u001b[0m     hparams,\n\u001b[1;32m     30\u001b[0m     iterator_creator,\n\u001b[1;32m     31\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m ):\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialization steps for NRMS.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Compared with the BaseModel, NRMS need word embedding.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    After creating word embedding matrix, BaseModel's __init__ method will be called.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        iterator_creator_test (object): NRMS data loader class for test and validation data\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2vec_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwordEmb_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     45\u001b[0m         hparams,\n\u001b[1;32m     46\u001b[0m         iterator_creator,\n\u001b[1;32m     47\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m     48\u001b[0m     )\n",
      "File \u001b[0;32m~/nrms_tf/lib/python3.10/site-packages/recommenders/models/newsrec/models/base_model.py:89\u001b[0m, in \u001b[0;36mBaseModel._init_embedding\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_embedding\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load pre-trained embeddings as a constant tensor.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m        numpy.ndarray: A constant numpy array.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nrms_tf/lib/python3.10/site-packages/numpy/lib/npyio.py:462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load file containing pickled data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen allow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(fid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "### NOTE\n",
    "##\n",
    "'''\n",
    "You'll need to make this look like the below so vi the file. \n",
    "\n",
    "vi ~/nrms_tf/lib/python3.10/site-packages/recommenders/models/newsrec/models/layers.py\n",
    "\n",
    "\n",
    "#import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat.v1.linalg import einsum\n",
    "#from tensorflow.compat.v1.keras import layers\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "from recommenders.models.newsrec.models.nrms import NRMSModel\n",
    "\n",
    "# Initialize hyperparameters (assuming hparams is already defined)\n",
    "iterator_creator = MINDIterator\n",
    "\n",
    "# Initialize the NRMS model with both hparams and iterator_creator\n",
    "model = NRMSModel(hparams, iterator, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160a7823-8d34-4ca6-8666-751f13af60bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mNRMSModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mNRMSModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"NRMS model(Neural News Recommendation with Multi-Head Self-Attention)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Chuhan Wu, Fangzhao Wu, Suyu Ge, Tao Qi, Yongfeng Huang,and Xing Xie, \"Neural News\u001b[0m\n",
       "\u001b[0;34m    Recommendation with Multi-Head Self-Attention\" in Proceedings of the 2019 Conference\u001b[0m\n",
       "\u001b[0;34m    on Empirical Methods in Natural Language Processing and the 9th International Joint Conference\u001b[0m\n",
       "\u001b[0;34m    on Natural Language Processing (EMNLP-IJCNLP)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes:\u001b[0m\n",
       "\u001b[0;34m        word2vec_embedding (numpy.ndarray): Pretrained word embedding matrix.\u001b[0m\n",
       "\u001b[0;34m        hparam (object): Global hyper-parameters.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0miterator_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Initialization steps for NRMS.\u001b[0m\n",
       "\u001b[0;34m        Compared with the BaseModel, NRMS need word embedding.\u001b[0m\n",
       "\u001b[0;34m        After creating word embedding matrix, BaseModel's __init__ method will be called.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            hparams (object): Global hyper-parameters. Some key setttings such as head_num and head_dim are there.\u001b[0m\n",
       "\u001b[0;34m            iterator_creator_train (object): NRMS data loader class for train data.\u001b[0m\n",
       "\u001b[0;34m            iterator_creator_test (object): NRMS data loader class for test and validation data\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordEmb_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0miterator_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_input_label_from_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"get input and labels for trainning from iterator\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            batch data: input batch data from iterator\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            list: input feature fed into model (clicked_title_batch & candidate_title_batch)\u001b[0m\n",
       "\u001b[0;34m            numpy.ndarray: labels\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minput_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clicked_title_batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"candidate_title_batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minput_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0minput_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_label\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_user_feature_from_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"get input of user encoder\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            batch_data: input batch data from user iterator\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            numpy.ndarray: input user feature (clicked title batch)\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clicked_title_batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_get_news_feature_from_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"get input of news encoder\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            batch_data: input batch data from news iterator\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            numpy.ndarray: input news feature (candidate title batch)\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"candidate_title_batch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Build NRMS model and scorer.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            object: a model used to train.\u001b[0m\n",
       "\u001b[0;34m            object: a model used to evaluate and inference.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_nrms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_build_userencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitleencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"The main function to create user encoder of NRMS.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            titleencoder (object): the news encoder of NRMS.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Return:\u001b[0m\n",
       "\u001b[0;34m            object: the user encoder of NRMS.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhis_input_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclick_title_presents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitleencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis_input_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mclick_title_presents\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0muser_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttLayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_hidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis_input_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_present\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"user_encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_build_newsencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"The main function to create news encoder of NRMS.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            embedding_layer (object): a word embedding layer.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Return:\u001b[0m\n",
       "\u001b[0;34m            object: the news encoder of NRMS.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msequences_input_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0membedded_sequences_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_input_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_sequences_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpred_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttLayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_hidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_input_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"news_encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_build_nrms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"The main function to create NRMS's logic. The core of NRMS\u001b[0m\n",
       "\u001b[0;34m        is a user encoder and a news encoder.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            object: a model used to train.\u001b[0m\n",
       "\u001b[0;34m            object: a model used to evaluate and inference.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhis_input_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpred_input_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpratio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpred_input_title_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpred_title_one_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpred_input_title_one\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtitleencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_newsencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_userencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitleencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewsencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitleencoder\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0muser_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis_input_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnews_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewsencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_input_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnews_present_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewsencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_title_one_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnews_present\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_present\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpred_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnews_present_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_present\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpred_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhis_input_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_input_title\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhis_input_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_input_title_one\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/nrms_tf/lib/python3.10/site-packages/recommenders/models/newsrec/models/nrms.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NRMSModel??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c66b2-4688-4ac9-ab66-0fe2383bca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = hparams.wordDict_file\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        print(\"Successfully loaded:\", data)\n",
    "except pickle.UnpicklingError as e:\n",
    "    print(\"UnpicklingError:\", e)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4244e-4dee-4ee0-a34d-ea65ecef0945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e9383-77e6-4036-a323-8fd31c26b2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb622dff-5e9a-4646-ada1-f64286d775db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize Tokenizer with a fixed vocabulary size (e.g., 50,000 as per the NRMS paper)\n",
    "vocab_size = 50000\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")  # OOV token for out-of-vocabulary words\n",
    "\n",
    "# Fit the tokenizer on the combined text data (news titles and user histories)\n",
    "all_titles = df_news['title'].tolist()\n",
    "all_histories = df_behaviors['history'].fillna('').tolist()  # Fill NA with empty strings\n",
    "tokenizer.fit_on_texts(all_titles + all_histories)\n",
    "\n",
    "# Convert news titles to sequences and pad them to a fixed length\n",
    "max_title_length = 30  # Based on NRMS paper\n",
    "title_sequences = tokenizer.texts_to_sequences(df_news['title'])\n",
    "title_sequences_padded = pad_sequences(title_sequences, maxlen=max_title_length, padding='post')\n",
    "\n",
    "# Convert user histories to sequences and pad them to a fixed length\n",
    "max_history_length = 50  # Based on NRMS paper\n",
    "history_sequences = tokenizer.texts_to_sequences(df_behaviors['history'].fillna(''))\n",
    "history_sequences_padded = pad_sequences(history_sequences, maxlen=max_history_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14dd7b9-d998-4e16-b54b-676975d2c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load MIND Dataset\n",
    "# Now, we will load the MIND dataset, which contains user behaviors and news articles.\n",
    "# We have the datasets already downloaded in ~/datasets/MINDlarge and ~/datasets/MINDsmall.\n",
    "mind_large = '~/datasets/MINDlarge'\n",
    "mind_large_train = mind_large + '/train/'\n",
    "mind_large_dev = mind_large + '/dev/'  # Development -- help tune hyper-parameter \n",
    "mind_large_test = mind_large + '/test/'\n",
    "\n",
    "mind_small = '~/datasets/MINDsmall'\n",
    "mind_small_train = mind_small + '/train/'\n",
    "mind_small_dev = mind_small + '/dev/'\n",
    "\n",
    "dataset_path = mind_small_train\n",
    "\n",
    "# Load training data\n",
    "df_behaviors = pd.read_csv(f\"{dataset_path}behaviors.tsv\", sep=\"\\t\", names=[\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"])\n",
    "df_news = pd.read_csv(f\"{dataset_path}news.tsv\", sep=\"\\t\", names=[\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be8b66-0212-444b-8598-9f7e7c058f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Preprocessing\n",
    "# Check for missing values in the title column and remove them.\n",
    "df_news = df_news[df_news['title'].notna()].copy()\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# The next step is to preprocess the news dataset. We tokenize the news titles using BERT tokenizer.\n",
    "def preprocess_news(news_df):\n",
    "    # Tokenize the news title using the BERT tokenizer\n",
    "    news_df.loc[:, 'title_tokens'] = news_df['title'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=50, truncation=True))\n",
    "    return news_df\n",
    "\n",
    "df_news = preprocess_news(df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780cfcb-1192-4529-859e-d294c1e6254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Vocabulary\n",
    "# BERT tokenizer already provides the vocabulary, so no need to create a custom vocabulary.\n",
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a879182-33b4-4be1-bd85-edc3264d9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Dataset and DataLoader Classes\n",
    "# We define a custom Dataset class to load and serve the data to the model. This class will convert news titles and user behaviors into tensors.\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, df_behaviors, df_news):\n",
    "        self.behaviors = df_behaviors\n",
    "        self.news = df_news\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.behaviors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract user history and impressions from the behaviors dataset.\n",
    "        user_history = self.behaviors.iloc[idx]['history'].split()\n",
    "        impressions = self.behaviors.iloc[idx]['impressions'].split()\n",
    "        # Get the tokenized titles for each news article in the user's history.\n",
    "        news_titles = []\n",
    "        for news_id in user_history:\n",
    "            matching_news = self.news[self.news['news_id'] == news_id]\n",
    "            if not matching_news.empty:\n",
    "                news_titles.append(matching_news['title_tokens'].values[0])\n",
    "        if not news_titles:\n",
    "            # If no valid news articles are found, return an empty tensor with padding\n",
    "            news_titles = [[0]]\n",
    "        return torch.tensor(news_titles, dtype=torch.long), torch.tensor([1 if '1' in imp else 0 for imp in impressions])\n",
    "\n",
    "# Create the dataset and dataloader for training.\n",
    "train_dataset = NewsDataset(df_behaviors, df_news)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e10c2-0aee-44c7-8c67-8fd8687babb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define the NRMS Model\n",
    "# Here, we define the NRMS model. The model uses BERT embeddings and a multi-head attention mechanism to capture the relationships between words.\n",
    "class NRMS(nn.Module):\n",
    "    def __init__(self, embedding_dim, attention_heads):\n",
    "        super(NRMS, self).__init__()\n",
    "        # BERT model to get embeddings\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Multi-head attention layer to capture interactions between words.\n",
    "        self.attention = nn.MultiheadAttention(embedding_dim, attention_heads)\n",
    "        # Fully connected layer to produce the final output.\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert input sequences to embeddings using BERT.\n",
    "        with torch.no_grad():\n",
    "            x = self.bert(x)[0]  # Extract the last hidden state from BERT\n",
    "        x = x.permute(1, 0, 2)  # Convert to (SeqLen, Batch, EmbeddingDim)\n",
    "        # Apply multi-head attention.\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        # Average pooling over sequence length and pass through a fully connected layer.\n",
    "        out = self.fc(attn_output.mean(dim=0))\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87979b24-37c7-4573-b694-1d4a4adab340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Training Loop\n",
    "# We define the training loop to train the NRMS model on the MIND dataset.\n",
    "model = NRMS(embedding_dim, attention_heads)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification.\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimizer.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for news_tokens, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        # Move data to the appropriate device (CPU or GPU).\n",
    "        news_tokens, labels = news_tokens.to(device), labels.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()  # Clear previous gradients.\n",
    "        outputs = model(news_tokens)  # Forward pass through the model.\n",
    "        loss = criterion(outputs.view(-1), labels.view(-1))  # Calculate loss.\n",
    "        loss.backward()  # Backpropagate the loss.\n",
    "        optimizer.step()  # Update model parameters.\n",
    "        epoch_loss += loss.item()\n",
    "    # Print the average loss for the epoch.\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Step 8: Save the Model\n",
    "# Finally, save the trained model so it can be used for inference or further training.\n",
    "torch.save(model.state_dict(), 'nrms_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb1ea4-b13b-479e-9568-fb130ce8384b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6545d-04a4-4521-b918-cab868602d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Step 1: Define Parameters\n",
    "# We start by defining some important parameters for our model such as embedding dimensions, number of attention heads, batch size, etc.\n",
    "embedding_dim = 768  # Using BERT embedding dimensions\n",
    "attention_heads = 8  # Number of attention heads in multi-head attention\n",
    "batch_size = 16  # Number of samples in each batch\n",
    "num_epochs = 10  # Number of epochs to train the model\n",
    "learning_rate = 0.001  # Learning rate for the optimizer\n",
    "\n",
    "# Step 2: Load MIND Dataset\n",
    "# Now, we will load the MIND dataset, which contains user behaviors and news articles.\n",
    "# We have the datasets already downloaded in ~/datasets/MINDlarge and ~/datasets/MINDsmall.\n",
    "mind_large = '~/datasets/MINDlarge'\n",
    "mind_large_train = mind_large + '/train/'\n",
    "mind_large_dev = mind_large + '/dev/'  # Development -- help tune hyper-parameter \n",
    "mind_large_test = mind_large + '/test/'\n",
    "\n",
    "mind_small = '~/datasets/MINDsmall'\n",
    "mind_small_train = mind_small + '/train/'\n",
    "mind_small_dev = mind_small + '/dev/'\n",
    "\n",
    "dataset_path = mind_small_train\n",
    "\n",
    "# Load training data\n",
    "df_behaviors = pd.read_csv(f\"{dataset_path}behaviors.tsv\", sep=\"\\t\", names=[\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"])\n",
    "df_news = pd.read_csv(f\"{dataset_path}news.tsv\", sep=\"\\t\", names=[\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"entity\"])\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "# Check for missing values in the title column and remove them.\n",
    "df_news = df_news[df_news['title'].notna()].copy()\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# The next step is to preprocess the news dataset. We tokenize the news titles using BERT tokenizer.\n",
    "def preprocess_news(news_df):\n",
    "    # Tokenize the news title using the BERT tokenizer\n",
    "    news_df.loc[:, 'title_tokens'] = news_df['title'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=50, truncation=True))\n",
    "    return news_df\n",
    "\n",
    "df_news = preprocess_news(df_news)\n",
    "\n",
    "# Step 4: Create Vocabulary\n",
    "# BERT tokenizer already provides the vocabulary, so no need to create a custom vocabulary.\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "# Step 5: Dataset and DataLoader Classes\n",
    "# We define a custom Dataset class to load and serve the data to the model. This class will convert news titles and user behaviors into tensors.\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, df_behaviors, df_news):\n",
    "        self.behaviors = df_behaviors\n",
    "        self.news = df_news\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.behaviors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract user history and impressions from the behaviors dataset.\n",
    "        user_history = str(self.behaviors.iloc[idx]['history']).split()\n",
    "        impressions = str(self.behaviors.iloc[idx]['impressions']).split()\n",
    "        # Get the tokenized titles for each news article in the user's history.\n",
    "        news_titles = []\n",
    "        for news_id in user_history:\n",
    "            matching_news = self.news[self.news['news_id'] == news_id]\n",
    "            if not matching_news.empty:\n",
    "                news_titles.append(matching_news['title_tokens'].values[0])\n",
    "        if not news_titles:\n",
    "            # If no valid news articles are found, return a tensor filled with padding\n",
    "            news_titles = [[0]]\n",
    "        # Convert list of token lists to tensors\n",
    "        news_titles = [torch.tensor(tokens, dtype=torch.long) for tokens in news_titles]\n",
    "        labels = torch.tensor([1 if '1' in imp else 0 for imp in impressions], dtype=torch.float)\n",
    "        return news_titles, labels\n",
    "\n",
    "# Custom collate function to handle batches with varying sequence lengths\n",
    "def collate_fn(batch):\n",
    "    news_titles_batch, labels_batch = zip(*batch)\n",
    "    # Pad each list of news titles independently\n",
    "    padded_news_titles = [pad_sequence(news, batch_first=True, padding_value=0) for news in news_titles_batch]\n",
    "    # Stack all padded news titles into a batch\n",
    "    news_titles_padded = pad_sequence(padded_news_titles, batch_first=True, padding_value=0)\n",
    "    # Pad labels to ensure consistent batch size\n",
    "    labels_padded = pad_sequence(labels_batch, batch_first=True, padding_value=0)\n",
    "    # Create attention masks\n",
    "    attention_mask = (news_titles_padded != 0).long()\n",
    "    return news_titles_padded, attention_mask, labels_padded\n",
    "\n",
    "# Create the dataset and dataloader for training.\n",
    "train_dataset = NewsDataset(df_behaviors, df_news)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Step 6: Define the NRMS Model\n",
    "# Here, we define the NRMS model. The model uses BERT embeddings and a multi-head attention mechanism to capture the relationships between words.\n",
    "class NRMS(nn.Module):\n",
    "    def __init__(self, embedding_dim, attention_heads):\n",
    "        super(NRMS, self).__init__()\n",
    "        # BERT model to get embeddings\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Multi-head attention layer to capture interactions between words.\n",
    "        self.attention = nn.MultiheadAttention(embedding_dim, attention_heads)\n",
    "        # Fully connected layer to produce the final output.\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, x, attention_mask):\n",
    "        # Convert input sequences to embeddings using BERT.\n",
    "        with torch.no_grad():\n",
    "            x = self.bert(x, attention_mask=attention_mask)[0]  # Extract the last hidden state from BERT\n",
    "        x = x.permute(1, 0, 2)  # Convert to (SeqLen, Batch, EmbeddingDim)\n",
    "        # Apply multi-head attention.\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        # Average pooling over sequence length and pass through a fully connected layer.\n",
    "        out = self.fc(attn_output.mean(dim=0))\n",
    "        return torch.sigmoid(out).squeeze()\n",
    "\n",
    "# Step 7: Training Loop\n",
    "# We define the training loop to train the NRMS model on the MIND dataset.\n",
    "model = NRMS(embedding_dim, attention_heads)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification.\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimizer.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for news_tokens, attention_mask, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        # Move data to the appropriate device (CPU or GPU).\n",
    "        news_tokens, attention_mask, labels = news_tokens.to(device), attention_mask.to(device), labels.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()  # Clear previous gradients.\n",
    "        outputs = model(news_tokens, attention_mask)  # Forward pass through the model.\n",
    "        loss = criterion(outputs.view(-1), labels.view(-1))  # Calculate loss.\n",
    "        loss.backward()  # Backpropagate the loss.\n",
    "        optimizer.step()  # Update model parameters.\n",
    "        epoch_loss += loss.item()\n",
    "    # Print the average loss for the epoch.\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Step 8: Save the Model\n",
    "# Finally, save the trained model so it can be used for inference or further training.\n",
    "torch.save(model.state_dict(), 'nrms_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c78d6-9abf-421e-9442-1c1e26bfd7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c42b3378-bc93-413b-8cab-ea9581a73938",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://wuch15.github.io/paper/EMNLP2019-NRMS.pdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cc39b-cd95-4be9-9520-bfca4eead210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
