version: '3.8'

networks:
  cicero:
    driver: bridge

services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    networks:
      - cicero
    ports:
      - "11434:11434"
    volumes:
      - /home/asheller/ollama_models:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  open-webui:
    build:
      context: .
      dockerfile: Dockerfile.owui
    container_name: open-webui-container
    networks:
      - cicero
    ports:
      - "8080:8080"
    volumes:
      - ./openwebui-data:/app/backend # Persist open-webui data
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  fabric:
    build:
      context: .
      dockerfile: Dockerfile.fabric
    container_name: fabric-container
    networks:
      - cicero
    volumes:
      - ./fabric-config:/home/fab_user/.config/fabric
    ports:
      - "8000:8000"
    stdin_open: true
    tty: true

  suber:
    build:
      context: .
      dockerfile: Dockerfile.suber
    container_name: suber-container
    runtime: nvidia  # GPU support
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    networks:
      - cicero
    volumes:
      - ./SUBERX:/app/SUBERX  # Mount SUBERX directory to the container
    ports:
      - "8889:8889"  # Expose JupyterLab port for suber
    stdin_open: true  # Keep STDIN open
    tty: true  # Allocate a pseudo-TTY
    ipc: host  # Equivalent to --ipc=host
    ulimits:
      memlock:
        soft: -1
        hard: -1
      stack:
        soft: 67108864
        hard: 67108864



  nrms:
    build:
      context: .
      dockerfile: Dockerfile.nrms
    container_name: nrms-container
    runtime: nvidia  # For GPU support
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./nrms:/app/nrms  # Mount your local nrms folder to the container
      - ./nrms_data:/app/nrms_data  # Mount directory for data persistence
    ports:
      - "8888:8888"  # Expose JupyterLab port
    stdin_open: true  # Keep STDIN open
    tty: true  # Allocate a pseudo-TTY
