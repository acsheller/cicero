{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f90f37-d975-49cc-9ff8-e118b25232ae",
   "metadata": {},
   "source": [
    "# System Preparation \n",
    "\n",
    "This notebook serves as notes for reference to getting setup to develop with SUBER.\n",
    "\n",
    "- [GPU Preparation](#gpu_prep)\n",
    "- [PyTorch Installation](#torch_install)\n",
    "- [Pytorch Examples]()\n",
    "- [Transformers and Tokenizers]()\n",
    "\n",
    "TODO -- fix links above.\n",
    "\n",
    "## Conda or Python Virtual Environments\n",
    "I switched to ordinary Python virtual environments because Anaconda itself was becoming a chore.  Why would it not simply add the mdodule I wanted?  It would take forever and stall in many cases.  The Python version used for this project is Python 3.10.12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9042aca-73bd-4764-a169-56a8188bd4b9",
   "metadata": {},
   "source": [
    "## <a href=\"gpu_prep\">GPU Preparation</a>\n",
    "\n",
    "GPU and nvcc (aka cuda) versions should be within the same major version. I've noticed that Ubuntu 22.04 loads on some systems have been way out of **alignment**. Try to get them at the same version.\n",
    "\n",
    "\n",
    "```\n",
    "sudo apt-get purge 'nvidia*' 'cuda*'\n",
    "\n",
    "sudo apt-get install nvidia-driver-535\n",
    "\n",
    "sudo reboot\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run\n",
    "\n",
    "chmod a+x cuda_12.2.0_535.54.03_linux.run\n",
    " \n",
    "sudo ./cuda_12.2.0_535.54.03_linux.run # And follow the prompts\n",
    "\n",
    "# Edit your .bashrc and put these in. But don't put the hastags in front of them.\n",
    "# export PATH=/usr/local/cuda-12.2/bin${PATH:+:${PATH}}\n",
    "#export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "\n",
    "\n",
    "# I also had to do this.  If you cannot type nvcc --version then you need to check the permissions.\n",
    "sudo chmod -R 755 /usr/local/cuda-12.2\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The results should be something like this:\n",
    "\n",
    "```\n",
    "acshell@ip-10-114-92-249:~$ nvidia-smi | grep -i \"cuda version\" | awk '{print $9}'\n",
    "12.2\n",
    "acshell@ip-10-114-92-249:~$ nvcc --version\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2023 NVIDIA Corporation\n",
    "Built on Tue_Jun_13_19:16:58_PDT_2023\n",
    "Cuda compilation tools, release 12.2, V12.2.91\n",
    "Build cuda_12.2.r12.2/compiler.32965470_0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7795877-6869-4f73-8b4d-200276e90df9",
   "metadata": {},
   "source": [
    "## <a href=torch_install>Torch Installation<a/>\n",
    "\n",
    "You should do this first. If this doesn't work, nothing will. \n",
    "\n",
    "PyTorch cuda version should be within a minor version of the cuda drivers and cuda drivers need to align with nvidia drivers.  Try hard to make this happen by paying attention to versions.  \n",
    "\n",
    "```.bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed9f27e-d2b1-4613-8d06-c06b088ecca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available? True.\n",
      "Torch Cuda Version is 2.4.1+cu118.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(f\"Is Cuda available? {torch.cuda.is_available()}.\")  # Should return True\n",
    "print(f\"Torch Cuda Version is {torch.__version__}.\")  # Should return '12.1'\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d74b6bd-748d-4de1-9d9f-cd3e453d3781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch can use the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737d4e6d-a533-4b7b-8f43-3063a5e016f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print(\"Current GPU Device:\", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a3b4e7-7610-448c-8989-f527582c15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu118\n",
      "CUDA is available! PyTorch can use the GPU.\n",
      "Current GPU Device: NVIDIA GeForce RTX 3060\n",
      "Number of GPUs available: 1\n",
      "Current CUDA version: 2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU.\")\n",
    "    print(\"Current GPU Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA version:\", torch.__version__)\n",
    "else:\n",
    "    print(\"CUDA is NOT available. PyTorch is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4729f-6f5c-4154-9465-ddc6c117b774",
   "metadata": {},
   "source": [
    "### Torch Examples\n",
    "\n",
    "Here are some examples showing that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc3da4c-9a5b-433e-a7f4-c8a2c6fdfb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication on CPU took: 3.6496 seconds\n",
      "Result tensor size on CPU: torch.Size([10000, 10000])\n",
      "Matrix multiplication on GPU took: 0.3066 seconds\n",
      "Result tensor size on GPU: torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the size of the tensors\n",
    "size = 10000\n",
    "\n",
    "# Create two large random tensors for CPU\n",
    "tensor1_cpu = torch.randn(size, size)\n",
    "tensor2_cpu = torch.randn(size, size)\n",
    "\n",
    "# Perform matrix multiplication on the CPU and time it\n",
    "start_time = time.time()\n",
    "result_cpu = torch.matmul(tensor1_cpu, tensor2_cpu)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication on CPU took: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Result tensor size on CPU: {result_cpu.size()}\")\n",
    "\n",
    "# Check if CUDA is available and perform the same test on the GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Create two large random tensors for GPU\n",
    "    tensor1_gpu = tensor1_cpu.to(device)\n",
    "    tensor2_gpu = tensor2_cpu.to(device)\n",
    "\n",
    "    # Perform matrix multiplication on the GPU and time it\n",
    "    torch.cuda.synchronize()  # Ensure all CUDA operations are finished\n",
    "    start_time = time.time()\n",
    "    result_gpu = torch.matmul(tensor1_gpu, tensor2_gpu)\n",
    "    torch.cuda.synchronize()  # Ensure the GPU has finished the computation\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication on GPU took: {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Result tensor size on GPU: {result_gpu.size()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abb85a-a959-4938-b317-4c502d6b3ae4",
   "metadata": {},
   "source": [
    "## Stable Baselines 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fdeb1-9a02-454c-ac38-1f13c102a7be",
   "metadata": {},
   "source": [
    "## Install Stable Baselines 3\n",
    "\n",
    "```\n",
    "pip install stable-baselines3[extra]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6ed398-a51b-42b5-a509-a1fd94599c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses INFO, WARNING, and ERROR messages\n",
    "\n",
    "import stable_baselines3\n",
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2812c9-78a9-44a2-b997-431bc8498d51",
   "metadata": {},
   "source": [
    "### SB3 Example\n",
    "\n",
    "Note, it takes many iteraitons and the proper algorithm to get good results; this just shows it working.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066b6955-d608-4996-9f99-cba81995e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.9     |\n",
      "|    ep_rew_mean     | 19.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 527      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 26.8         |\n",
      "|    ep_rew_mean          | 26.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091266325 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | -0.00106     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.19         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 37.2      |\n",
      "|    ep_rew_mean          | 37.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 387       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0082108 |\n",
      "|    clip_fraction        | 0.0482    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.667    |\n",
      "|    explained_variance   | 0.0878    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 13.5      |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -0.0153   |\n",
      "|    value_loss           | 30        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.5        |\n",
      "|    ep_rew_mean          | 50.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 427         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006828722 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 56          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.8         |\n",
      "|    ep_rew_mean          | 66.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075615244 |\n",
      "|    clip_fraction        | 0.0597       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.616       |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 65.9         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "# Create the CartPole-v1 environment with the \"rgb_array\" render mode\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Create the PPO model (you can replace PPO with other algorithms if you want)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the agent for 10,000 steps\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Test the trained agent and render in the notebook\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Set up the plot for dynamic updates\n",
    "#plt.ion()  # Turn on interactive mode for matplotlib\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "\n",
    "    if done or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899a604-34d0-4299-be1c-96aaa804e34c",
   "metadata": {},
   "source": [
    "## Install Transformers and Tokenizers\n",
    "\n",
    "```\n",
    "pip install -U transformers tokenizers\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8825337-4ecb-483b-aff1-f649ee0d4f07",
   "metadata": {},
   "source": [
    "### Transformer and Tokenizer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b96fc0-bb19-4440-88f6-23db75f85940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Transformers are amazing for NLP tasks.\n",
      "Tokenized Input IDs: tensor([[  101, 19081,  2024,  6429,  2005, 17953,  2361,  8518,  1012,   102]])\n",
      "Decoded Text: transformers are amazing for nlp tasks.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',quiet=True)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text\n",
    "text = \"Transformers are amazing for NLP tasks.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get the tokenized input IDs\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# Decode the token IDs back to text\n",
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print original text, tokenized input, and decoded text\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Tokenized Input IDs:\", input_ids)\n",
    "print(\"Decoded Text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af7930-6087-4db5-82f9-ae56de146383",
   "metadata": {},
   "source": [
    "## Sentence Transformers\n",
    "\n",
    "```/bash\n",
    "pip install sentence-transformers\n",
    "\n",
    "```\n",
    "\n",
    "Need this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254201e2-3fb5-4f0f-a346-dfed1abb0264",
   "metadata": {},
   "source": [
    "### Sentence Transformers Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f76f3b-253d-4df7-af11-cac9ee1bd986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.13389623e-02 -2.08391678e-02  3.78195494e-02 -1.00276563e-02\n",
      "  -2.18986571e-02  6.64146105e-03 -4.42283079e-02  4.97135669e-02\n",
      "   2.80648377e-02  1.45602552e-02  2.62471847e-02  8.02668780e-02\n",
      "   4.97584604e-03  8.78880545e-02  4.61270176e-02  3.79768983e-02\n",
      "   3.22095938e-02  1.52603192e-02 -4.78855856e-02 -8.71268734e-02\n",
      "   1.09329350e-01  8.22059587e-02  1.47923548e-02 -5.11702932e-02\n",
      "   5.15240319e-02  6.55859411e-02 -5.36913276e-02 -4.96964008e-02\n",
      "   3.65458690e-02 -9.47062206e-03 -4.13956009e-02  5.72569109e-02\n",
      "  -6.83492124e-02  5.84685020e-02 -6.26849830e-02  7.58528113e-02\n",
      "   1.44350193e-02  1.83785912e-02  1.41708059e-02 -5.39688915e-02\n",
      "  -3.47521119e-02 -1.90681964e-02  1.80511549e-02 -2.25276779e-02\n",
      "   4.55971025e-02 -3.47322710e-02 -2.73608882e-02 -1.98490210e-02\n",
      "  -8.14894855e-04 -2.79270560e-02 -3.95562686e-02 -5.84855042e-02\n",
      "   5.34983538e-02  1.18243895e-01 -1.34977922e-02  2.81568505e-02\n",
      "   8.00178666e-03 -5.52489348e-02  1.07748285e-02 -8.26784745e-02\n",
      "  -7.50691816e-02 -7.26922182e-04 -1.14284577e-02 -3.15912552e-02\n",
      "  -2.56440099e-02 -8.93282983e-03  2.13977024e-02 -1.95719185e-03\n",
      "  -3.98999341e-02  1.71870179e-02 -9.86917093e-02  4.32079732e-02\n",
      "   2.14145724e-02  7.41939843e-02  8.17540959e-02  1.30179776e-02\n",
      "   3.96499597e-02 -1.12352595e-01  1.61440000e-02 -4.75933366e-02\n",
      "   7.10801706e-02 -2.49395948e-02 -1.67709868e-02  1.02371067e-01\n",
      "   6.00531586e-02 -3.79599966e-02 -8.91840784e-04 -1.67397577e-02\n",
      "  -8.11639279e-02 -2.96585448e-03 -8.68672207e-02 -9.48273167e-02\n",
      "   8.75561684e-02  7.51266582e-03 -4.40817103e-02  2.50664577e-02\n",
      "  -4.81076464e-02 -7.26852491e-02  4.49803565e-03  3.30109298e-02\n",
      "  -9.52916220e-03 -2.88514346e-02  2.91740727e-02 -9.59848911e-02\n",
      "  -1.13295592e-01 -7.04405829e-02 -1.06133549e-02  1.11098066e-02\n",
      "  -3.91735509e-03 -4.05783169e-02  3.17186564e-02 -2.89384443e-02\n",
      "  -1.91742945e-02 -4.31948230e-02  6.17150292e-02 -8.93388838e-02\n",
      "   8.42685625e-03 -1.18960757e-02 -2.79277191e-02  3.27752233e-02\n",
      "   1.35773877e-02  7.54369497e-02 -4.16411310e-02  7.63626471e-02\n",
      "   2.60961857e-02 -3.30173485e-02  9.69682485e-02 -2.01159758e-33\n",
      "   8.41610506e-03  9.49250087e-02  4.12811078e-02  3.72696593e-02\n",
      "  -9.30490158e-03  3.43330717e-03 -2.14503650e-02  5.93383163e-02\n",
      "  -3.82257327e-02 -3.54569103e-03 -5.11288904e-02  8.00575167e-02\n",
      "  -1.72845200e-02 -1.36362494e-03 -1.50901582e-02 -6.47913963e-02\n",
      "  -3.30008641e-02  4.24927734e-02 -3.90296727e-02  3.09746135e-02\n",
      "  -6.61239028e-03  4.67417799e-02  3.62695381e-02 -2.47308593e-02\n",
      "  -3.20474058e-02 -3.44660436e-03 -1.98133732e-03 -6.16286956e-02\n",
      "   4.73358184e-02 -1.84988435e-02 -3.48375365e-02  5.97698204e-02\n",
      "  -5.21448962e-02  2.64986157e-02  5.34058129e-03  2.45022750e-03\n",
      "  -2.50871759e-02 -9.50678214e-02 -1.16135776e-02 -1.79991685e-02\n",
      "  -2.73288246e-02  5.74762486e-02 -1.10659651e-01  7.15814810e-03\n",
      "   7.70750046e-02  7.02132359e-02  2.04947568e-03 -4.28030677e-02\n",
      "   2.79471800e-02  1.98840559e-03  3.78897116e-02  5.34534119e-02\n",
      "  -5.07847480e-02  1.97705370e-03  1.83810994e-01 -7.26304017e-03\n",
      "   3.04948520e-02 -4.95861191e-03  1.00949369e-01  2.92117856e-02\n",
      "  -1.23772211e-02  3.00229359e-02  1.59176625e-02 -3.04648429e-02\n",
      "   4.33325917e-02 -2.02232748e-02  5.77009842e-02 -3.25591536e-03\n",
      "  -3.42567451e-04 -1.16551500e-02 -2.14824751e-02 -3.31575982e-02\n",
      "  -8.43168120e-04 -3.40885818e-02  1.86595358e-02  1.45057561e-02\n",
      "   2.44680303e-03 -4.46444936e-02  4.31090742e-02  5.86921908e-02\n",
      "  -4.85015102e-02 -1.19012102e-01  2.97994241e-02 -4.78464738e-02\n",
      "   2.59547122e-02 -4.82602604e-02 -3.18483673e-02 -9.71545875e-02\n",
      "   4.57095401e-03 -9.06091928e-03 -8.83241592e-04  2.50313804e-02\n",
      "  -2.26742383e-02  4.16879961e-03  5.73513424e-03  9.56814106e-34\n",
      "  -3.73278707e-02 -1.25536006e-02 -1.03082277e-01  9.87607986e-02\n",
      "  -2.94563510e-02 -1.43612828e-02 -3.82837392e-02  2.79907994e-02\n",
      "   2.47577019e-02  5.60509302e-02 -8.17173533e-03 -3.16256583e-02\n",
      "  -3.93590517e-02 -2.18429118e-02  1.09794043e-01 -6.70883581e-02\n",
      "   4.63267937e-02 -1.40530225e-02  4.11659144e-02  8.68672058e-02\n",
      "   1.58836190e-02  1.58808157e-01 -1.29776910e-01  4.66320850e-02\n",
      "  -9.48791578e-03  6.40924871e-02 -1.15770929e-01  7.14267371e-03\n",
      "   1.17837777e-02  9.03237052e-03 -4.31012772e-02 -1.03710378e-02\n",
      "  -1.86151695e-02 -2.15607435e-02 -5.08089624e-02 -1.17473602e-02\n",
      "  -2.72202957e-02 -1.23247132e-02 -2.62996163e-02  1.65909510e-02\n",
      "   3.03094499e-02  3.99106108e-02 -2.81111095e-02  2.47760992e-02\n",
      "  -9.52601656e-02 -6.82688430e-02 -3.33690643e-02 -4.25384231e-02\n",
      "  -2.54370226e-03  7.71383867e-02 -3.54083590e-02  1.09947305e-02\n",
      "  -1.12818182e-01 -1.21028446e-01 -1.52590349e-02 -5.44914119e-02\n",
      "   5.40056154e-02 -1.03101231e-01  2.88094524e-02 -1.97712351e-02\n",
      "  -9.30150673e-02  2.82325316e-02  8.50701183e-02 -5.99852353e-02\n",
      "   2.28141993e-02 -3.07087004e-02  1.59087908e-02 -2.78399084e-02\n",
      "  -2.87897675e-03 -2.72179004e-02  6.62282631e-02  3.70688364e-02\n",
      "   2.64303237e-02 -3.94684933e-02 -1.07483435e-02 -1.19047798e-02\n",
      "   4.18200493e-02  7.88506586e-03 -2.53780652e-02 -6.98991641e-02\n",
      "   3.05061936e-02  8.73474125e-03  5.21765165e-02  2.98741851e-02\n",
      "   1.51348673e-02  8.98343176e-02 -1.84008684e-02  1.12339912e-03\n",
      "   3.24808806e-02  6.21275678e-02 -3.42305973e-02  3.46833616e-02\n",
      "   2.67563518e-02  1.13286503e-01  1.31214336e-02 -1.58217173e-08\n",
      "  -5.14110960e-02  5.96944094e-02 -3.73664275e-02 -1.06354784e-02\n",
      "  -1.42139634e-02 -4.84035499e-02  3.31887901e-02  8.29869956e-02\n",
      "  -3.32707390e-02 -3.35284800e-04  9.80553105e-02 -4.55461368e-02\n",
      "   9.90807544e-03  4.91860993e-02  1.17603995e-01  1.87714193e-02\n",
      "   7.86552504e-02 -6.34168368e-03 -3.67030352e-02  8.07174109e-03\n",
      "  -8.98543280e-04  8.72058198e-02 -5.00192642e-02  8.99781100e-03\n",
      "  -2.44703200e-02  2.10707355e-02 -3.14436071e-02 -4.93638702e-02\n",
      "   2.44295131e-02 -1.39967306e-02  3.58098419e-03  4.92439158e-02\n",
      "  -2.20063124e-02  4.35395315e-02  5.47413640e-02  2.43604854e-02\n",
      "   7.40203485e-02 -7.40141124e-02 -1.90981701e-02 -3.42055634e-02\n",
      "   7.88777396e-02  7.65522271e-02 -9.69668478e-02  3.22016776e-02\n",
      "   4.90539558e-02 -2.78659374e-03  4.22286689e-02 -1.70268372e-01\n",
      "  -3.40080857e-02  3.91164608e-03  7.40144821e-03 -2.76136696e-02\n",
      "  -4.57474142e-02  2.54089721e-02  7.90525526e-02  3.73700410e-02\n",
      "   4.22542877e-02 -7.54245594e-02 -5.92881516e-02  7.13606551e-02\n",
      "   1.18064974e-02  7.82025307e-02  1.94492452e-02  4.77531999e-02]\n",
      " [-3.65062431e-03 -4.02566530e-02  5.37925661e-02  1.87592693e-02\n",
      "   4.36548665e-02  1.07265882e-01  1.37051949e-02  5.64765856e-02\n",
      "   3.83178182e-02 -3.81296352e-02  4.78521958e-02  4.42149416e-02\n",
      "   2.23990604e-02  6.06395788e-02  2.15431470e-02  3.58680189e-02\n",
      "   8.68859813e-02  9.80533287e-02 -7.73597136e-02 -8.74792635e-02\n",
      "  -4.10939418e-02  2.51762755e-02  6.71608225e-02 -6.30396977e-02\n",
      "   7.63509143e-03 -9.63678770e-03 -6.72210306e-02  3.96239944e-03\n",
      "   6.95275813e-02  2.14077216e-02 -2.73870165e-03 -4.66554053e-03\n",
      "  -2.08296590e-02  2.78403498e-02 -1.73364617e-02  2.82478798e-02\n",
      "   4.42461409e-02  1.06463172e-01 -4.13178988e-02 -2.04074699e-02\n",
      "   8.36504065e-03  2.78143287e-02  5.13443910e-02  6.12559505e-02\n",
      "   5.86419888e-02 -5.18060327e-02 -6.59484565e-02 -2.18247343e-02\n",
      "  -4.19921614e-02  4.15930375e-02 -6.09701723e-02 -2.82707401e-02\n",
      "  -3.88227776e-02  2.98456196e-02  2.10315622e-02 -6.47070026e-03\n",
      "  -3.32621410e-02 -1.17579140e-02  1.10785337e-02 -9.81175080e-02\n",
      "   1.67629775e-02 -5.59938587e-02 -3.41848657e-02  4.53319252e-02\n",
      "   3.42978835e-02 -6.97385194e-03  3.40201589e-03  5.35050333e-02\n",
      "  -5.67048378e-02  1.18010826e-01 -3.72043662e-02  2.63290815e-02\n",
      "  -8.92801359e-02  3.48124243e-02 -7.75280967e-02  4.94074933e-02\n",
      "   5.68245761e-02 -1.02483302e-01  6.50745630e-02 -2.24783588e-02\n",
      "  -3.21006067e-02 -2.35491842e-02  1.46478228e-02 -1.28407963e-03\n",
      "   1.17351905e-01 -1.12275006e-02  7.39701316e-02 -6.42865300e-02\n",
      "  -6.89552128e-02  2.77737193e-02  8.26349389e-03 -7.05972612e-02\n",
      "   4.64272350e-02 -6.82025449e-03  9.92724393e-03 -1.55898584e-02\n",
      "  -3.29161584e-02 -2.54919846e-02  1.22037875e-02  6.56327829e-02\n",
      "   3.29815410e-02  2.29997188e-02  7.80922025e-02  3.18650785e-03\n",
      "  -4.98883463e-02 -3.59912030e-02 -2.51076557e-02  1.59666073e-02\n",
      "   3.59946908e-03 -7.74265975e-02 -1.08642399e-01  4.89925928e-02\n",
      "  -2.34071687e-02  1.15038631e-02  5.48987575e-02 -2.53492761e-02\n",
      "   1.77409071e-02 -5.13560213e-02  4.09484580e-02 -1.90766845e-02\n",
      "  -2.71398220e-02  5.08161038e-02 -4.04529199e-02  4.74189781e-02\n",
      "   1.87084321e-02 -7.64882863e-02  1.77136380e-02 -3.10000636e-33\n",
      "  -1.21809077e-02  2.59610023e-02 -1.91357657e-02  6.19516559e-02\n",
      "   9.14466474e-03  1.42611181e-02 -4.55985107e-02  6.13453463e-02\n",
      "  -8.51536468e-02 -3.42709795e-02 -3.82091850e-02  5.97606525e-02\n",
      "   1.83344614e-02  1.04791010e-02  5.01672104e-02  1.86542813e-02\n",
      "  -2.31891833e-02  1.37787983e-02  1.65510026e-03  2.48640701e-02\n",
      "  -5.38350269e-02 -1.85125731e-02 -2.82223267e-03 -3.37436087e-02\n",
      "  -3.69313471e-02 -2.38055512e-02  1.20403014e-01 -6.21039569e-02\n",
      "  -4.12108712e-02  2.42502689e-02 -5.59023432e-02 -3.04966904e-02\n",
      "  -6.82481602e-02 -1.79481339e-02  2.20061024e-03  1.10732820e-02\n",
      "   1.02061767e-03 -3.48261669e-02  1.49891712e-02 -8.75050295e-03\n",
      "  -5.40853245e-03 -2.03851052e-02 -9.91613697e-03  2.04786961e-03\n",
      "   1.04809133e-02  1.72008108e-03 -9.23036970e-03 -3.43418792e-02\n",
      "   1.65516548e-02 -4.56563383e-02  1.09757548e-02  2.34715119e-02\n",
      "  -3.89112881e-03 -1.08842522e-01  1.05601922e-01 -2.06439886e-02\n",
      "  -1.60452202e-02  1.41882813e-02  2.73804776e-02 -4.69093770e-02\n",
      "  -1.50368223e-02  1.98541842e-02  9.58695859e-02 -3.54821160e-02\n",
      "  -3.42407711e-02  7.78523833e-02 -5.04240766e-02 -2.30546743e-02\n",
      "   1.91291887e-02  2.52683535e-02 -6.17241561e-02  3.61112319e-02\n",
      "  -2.04769075e-02 -6.49498589e-03 -4.58281189e-02  6.94495067e-02\n",
      "  -5.43259233e-02 -1.00172482e-01  3.08690257e-02  1.17122799e-01\n",
      "  -3.66335851e-03 -1.84244558e-01  1.39171919e-02 -1.40380813e-02\n",
      "  -3.96210290e-02 -1.41388029e-01  5.43647073e-02 -8.71689245e-02\n",
      "   6.75088242e-02  2.89072506e-02 -1.67964101e-02 -9.78567172e-03\n",
      "  -4.55208905e-02 -1.96131947e-03 -2.68604010e-02  1.68949872e-33\n",
      "  -3.31909619e-02  1.94348432e-02 -6.68849349e-02  6.47820905e-02\n",
      "  -8.55547469e-03  2.43360996e-02 -6.32420331e-02  1.61888208e-02\n",
      "  -2.44753063e-02 -1.50398379e-02 -8.92010257e-02  1.34051973e-02\n",
      "   4.28511798e-02 -4.46366034e-02  2.76253540e-02  5.50354412e-03\n",
      "  -4.14503776e-02  2.03786548e-02 -1.62264127e-02  4.22022603e-02\n",
      "   1.41474558e-03  9.94223058e-02 -5.71460165e-02  7.38419890e-02\n",
      "   4.14964817e-02  8.90614837e-02 -6.04642145e-02 -7.20138028e-02\n",
      "  -1.31157145e-01 -5.55766523e-02 -3.43460850e-02 -4.77558300e-02\n",
      "  -3.85389216e-02 -4.77392226e-02 -5.84640168e-02  3.23132351e-02\n",
      "   7.33683258e-02 -4.08573635e-02 -1.83145255e-02 -3.50779928e-02\n",
      "   5.94206229e-02  5.31809144e-02 -1.55666079e-02  2.80934591e-02\n",
      "  -1.04945758e-02 -1.43888090e-02 -7.55968243e-02 -1.17197586e-02\n",
      "   7.57965297e-02  5.81873618e-02 -4.25755903e-02  3.81851494e-02\n",
      "  -8.37944597e-02 -5.61070107e-02 -1.72014590e-02 -5.63367344e-02\n",
      "   2.60048988e-03 -1.02772884e-01 -1.26566493e-03 -1.56447850e-02\n",
      "  -1.09514184e-01 -3.83284036e-03  3.97503451e-02 -4.62057628e-02\n",
      "   5.93802296e-02 -1.39045283e-01 -3.16912755e-02  6.14067540e-02\n",
      "  -2.19796877e-03 -9.27407891e-02  1.07508125e-02 -3.91481025e-03\n",
      "  -3.00360546e-02  5.58332913e-02 -3.05787865e-02 -2.35125814e-02\n",
      "   3.72293070e-02  1.56597272e-02 -6.71998486e-02 -6.47744089e-02\n",
      "   8.87671858e-02 -7.48190135e-02  6.93876669e-02 -3.46382782e-02\n",
      "   3.34317796e-02  7.62093589e-02  3.34793478e-02 -2.96905474e-03\n",
      "   2.07741354e-02 -8.93890113e-03 -6.33102879e-02 -1.24690933e-02\n",
      "  -1.75032225e-02  1.17574789e-01  3.06492932e-02 -1.57105973e-08\n",
      "  -6.15324378e-02 -2.43087709e-02  5.48808984e-02  3.30633000e-02\n",
      "  -7.56444484e-02 -7.11502060e-02 -2.29836516e-02  6.43548220e-02\n",
      "  -5.09497747e-02 -3.36611923e-03  5.79672903e-02  2.19356176e-02\n",
      "  -6.35054782e-02  1.38764046e-02  4.74085994e-02  4.33154479e-02\n",
      "   5.74719347e-03 -1.79616529e-02 -3.80586763e-03  2.26669870e-02\n",
      "   5.74051328e-02  1.11191213e-01 -6.37345016e-03  4.52824272e-02\n",
      "  -1.78189054e-02  3.89135145e-02  1.69905499e-02  3.40933651e-02\n",
      "   2.54978538e-02  2.16917489e-02  5.06390743e-02  8.18909928e-02\n",
      "  -9.80568025e-03  4.50544385e-03  4.65276241e-02  1.29042059e-01\n",
      "   7.15280175e-02 -1.00725032e-01 -2.45638395e-04 -3.17357061e-03\n",
      "   5.04630171e-02  6.68728128e-02 -8.23084339e-02  3.21189724e-02\n",
      "   1.00300290e-01  4.13456932e-03  2.14018710e-02 -4.83180620e-02\n",
      "  -4.03572731e-02  3.44825210e-03  3.83812003e-02 -5.31095676e-02\n",
      "   5.30551001e-03  1.54014453e-02  3.79170552e-02  3.94546129e-02\n",
      "   3.25821005e-02 -2.72933953e-02 -5.38103702e-03  3.48102376e-02\n",
      "  -9.61131509e-03  1.74200401e-01  3.71564776e-02 -4.88809496e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode a list of sentences\n",
    "sentences = [\"Transformers are amazing for NLP tasks.\", \"Sentence embeddings are useful.\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the sentence embeddings\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b173e6-2357-4ace-bdb7-fda7ac243c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbe4263a-5b09-4c82-9b14-77d8eefc3e3a",
   "metadata": {},
   "source": [
    "## Other Stuff\n",
    "\n",
    "If you are using Jupyter notebook, be sure to install `jupyterlab` and `ipywidgets` with pip.\n",
    "\n",
    "```.bash\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727ee5a-377c-42ed-95f0-01cc268afd01",
   "metadata": {},
   "source": [
    "## Setup Summary -- \n",
    "\n",
    "More notes can be added here but Pytorch, and Stable Baselines 3 are the two main modules.  Extras required from both will come up but should not be a huge issue.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
