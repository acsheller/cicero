{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f90f37-d975-49cc-9ff8-e118b25232ae",
   "metadata": {},
   "source": [
    "# System Preparation \n",
    "\n",
    "This notebook serves as notes for reference to getting setup to develop with SUBER.\n",
    "\n",
    "- [GPU Preparation](#gpu_prep)\n",
    "- [PyTorch Installation](#torch_install)\n",
    "- [Pytorch Examples]()\n",
    "- [Transformers and Tokenizers]()\n",
    "\n",
    "TODO -- fix links above.\n",
    "\n",
    "## Conda or Python Virtual Environments\n",
    "I switched to ordinary Python virtual environments because Anaconda itself was becoming a chore.  Why would it not simply add the mdodule I wanted?  It would take forever and stall in many cases.  The Python version used for this project is Python 3.10.12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9042aca-73bd-4764-a169-56a8188bd4b9",
   "metadata": {},
   "source": [
    "## <a href=\"gpu_prep\">GPU Preparation</a>\n",
    "\n",
    "GPU and nvcc (aka cuda) versions should be within the same major version. I've noticed that Ubuntu 22.04 loads on some systems have been way out of **alignment**. Try to get them at the same version.\n",
    "\n",
    "\n",
    "```\n",
    "sudo apt-get purge 'nvidia*' 'cuda*'\n",
    "\n",
    "sudo apt-get install nvidia-driver-535\n",
    "\n",
    "sudo reboot\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run\n",
    "\n",
    "chmod a+x cuda_12.2.0_535.54.03_linux.run\n",
    " \n",
    "sudo ./cuda_12.2.0_535.54.03_linux.run # And follow the prompts\n",
    "\n",
    "# Edit your .bashrc and put these in. But don't put the hastags in front of them.\n",
    "# export PATH=/usr/local/cuda-12.2/bin${PATH:+:${PATH}}\n",
    "#export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "\n",
    "\n",
    "# I also had to do this.  If you cannot type nvcc --version then you need to check the permissions.\n",
    "sudo chmod -R 755 /usr/local/cuda-12.2\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The results should be something like this:\n",
    "\n",
    "```\n",
    "acshell@ip-10-114-92-249:~$ nvidia-smi | grep -i \"cuda version\" | awk '{print $9}'\n",
    "12.2\n",
    "acshell@ip-10-114-92-249:~$ nvcc --version\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2023 NVIDIA Corporation\n",
    "Built on Tue_Jun_13_19:16:58_PDT_2023\n",
    "Cuda compilation tools, release 12.2, V12.2.91\n",
    "Build cuda_12.2.r12.2/compiler.32965470_0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7795877-6869-4f73-8b4d-200276e90df9",
   "metadata": {},
   "source": [
    "## <a href=torch_install>Torch Installation<a/>\n",
    "\n",
    "You should do this first. If this doesn't work, nothing will. \n",
    "\n",
    "PyTorch cuda version should be within a minor version of the cuda drivers and cuda drivers need to align with nvidia drivers.  Try hard to make this happen by paying attention to versions.  \n",
    "\n",
    "```.bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed9f27e-d2b1-4613-8d06-c06b088ecca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available? True.\n",
      "Torch Cuda Version is 2.4.1+cu124.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(f\"Is Cuda available? {torch.cuda.is_available()}.\")  # Should return True\n",
    "print(f\"Torch Cuda Version is {torch.__version__}.\")  # Should return '12.1'\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d74b6bd-748d-4de1-9d9f-cd3e453d3781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch can use the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737d4e6d-a533-4b7b-8f43-3063a5e016f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print(\"Current GPU Device:\", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a3b4e7-7610-448c-8989-f527582c15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu124\n",
      "CUDA is available! PyTorch can use the GPU.\n",
      "Current GPU Device: NVIDIA GeForce RTX 3060\n",
      "Number of GPUs available: 1\n",
      "Current CUDA version: 2.4.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU.\")\n",
    "    print(\"Current GPU Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA version:\", torch.__version__)\n",
    "else:\n",
    "    print(\"CUDA is NOT available. PyTorch is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4729f-6f5c-4154-9465-ddc6c117b774",
   "metadata": {},
   "source": [
    "### Torch Examples\n",
    "\n",
    "Here are some examples showing that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc3da4c-9a5b-433e-a7f4-c8a2c6fdfb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication on CPU took: 3.3440 seconds\n",
      "Result tensor size on CPU: torch.Size([10000, 10000])\n",
      "Matrix multiplication on GPU took: 0.2895 seconds\n",
      "Result tensor size on GPU: torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the size of the tensors\n",
    "size = 10000\n",
    "\n",
    "# Create two large random tensors for CPU\n",
    "tensor1_cpu = torch.randn(size, size)\n",
    "tensor2_cpu = torch.randn(size, size)\n",
    "\n",
    "# Perform matrix multiplication on the CPU and time it\n",
    "start_time = time.time()\n",
    "result_cpu = torch.matmul(tensor1_cpu, tensor2_cpu)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication on CPU took: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Result tensor size on CPU: {result_cpu.size()}\")\n",
    "\n",
    "# Check if CUDA is available and perform the same test on the GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Create two large random tensors for GPU\n",
    "    tensor1_gpu = tensor1_cpu.to(device)\n",
    "    tensor2_gpu = tensor2_cpu.to(device)\n",
    "\n",
    "    # Perform matrix multiplication on the GPU and time it\n",
    "    torch.cuda.synchronize()  # Ensure all CUDA operations are finished\n",
    "    start_time = time.time()\n",
    "    result_gpu = torch.matmul(tensor1_gpu, tensor2_gpu)\n",
    "    torch.cuda.synchronize()  # Ensure the GPU has finished the computation\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication on GPU took: {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Result tensor size on GPU: {result_gpu.size()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abb85a-a959-4938-b317-4c502d6b3ae4",
   "metadata": {},
   "source": [
    "## Stable Baselines 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fdeb1-9a02-454c-ac38-1f13c102a7be",
   "metadata": {},
   "source": [
    "## Install Stable Baselines 3\n",
    "\n",
    "```\n",
    "pip install stable-baselines3[extra]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6ed398-a51b-42b5-a509-a1fd94599c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses INFO, WARNING, and ERROR messages\n",
    "\n",
    "import stable_baselines3\n",
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2812c9-78a9-44a2-b997-431bc8498d51",
   "metadata": {},
   "source": [
    "### SB3 Example\n",
    "\n",
    "Note, it takes many iteraitons and the proper algorithm to get good results; this just shows it working.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066b6955-d608-4996-9f99-cba81995e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | 22.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 648      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 26.9       |\n",
      "|    ep_rew_mean          | 26.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 488        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00847777 |\n",
      "|    clip_fraction        | 0.0889     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | -0.0151    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.3        |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    value_loss           | 53.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34          |\n",
      "|    ep_rew_mean          | 34          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 447         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010674793 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.74        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.1        |\n",
      "|    ep_rew_mean          | 45.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008941104 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.627      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.1        |\n",
      "|    ep_rew_mean          | 60.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 420         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008377502 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 62.9        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "# Create the CartPole-v1 environment with the \"rgb_array\" render mode\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Create the PPO model (you can replace PPO with other algorithms if you want)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the agent for 10,000 steps\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Test the trained agent and render in the notebook\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Set up the plot for dynamic updates\n",
    "#plt.ion()  # Turn on interactive mode for matplotlib\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "\n",
    "    if done or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899a604-34d0-4299-be1c-96aaa804e34c",
   "metadata": {},
   "source": [
    "## Install Transformers and Tokenizers\n",
    "\n",
    "```\n",
    "pip install -U transformers tokenizers\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8825337-4ecb-483b-aff1-f649ee0d4f07",
   "metadata": {},
   "source": [
    "### Transformer and Tokenizer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b96fc0-bb19-4440-88f6-23db75f85940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f5400e83554440bce998844df5ef23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca5042062514ddeb88b31a376b582e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcf40cb6c3641b68346a6b54144c3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bcb6c338dc403087852d59cc685754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6340f724b17f4854bbffce1793015279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Transformers are amazing for NLP tasks.\n",
      "Tokenized Input IDs: tensor([[  101, 19081,  2024,  6429,  2005, 17953,  2361,  8518,  1012,   102]])\n",
      "Decoded Text: transformers are amazing for nlp tasks.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',quiet=True)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text\n",
    "text = \"Transformers are amazing for NLP tasks.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get the tokenized input IDs\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# Decode the token IDs back to text\n",
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print original text, tokenized input, and decoded text\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Tokenized Input IDs:\", input_ids)\n",
    "print(\"Decoded Text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af7930-6087-4db5-82f9-ae56de146383",
   "metadata": {},
   "source": [
    "## Sentence Transformers\n",
    "\n",
    "```/bash\n",
    "pip install sentence-transformers\n",
    "\n",
    "```\n",
    "\n",
    "Need this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254201e2-3fb5-4f0f-a346-dfed1abb0264",
   "metadata": {},
   "source": [
    "### Sentence Transformers Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f76f3b-253d-4df7-af11-cac9ee1bd986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ee867a37b04963bf42f76550b04958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94a65e96f8b430aa9e622fe4c1eed42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fc7c3c3fa7407e86e0d6460b9de7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c3118da39d43acb2fcdcc7ccc2a69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ea94f87bf14660958182ace400e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7c583bc3a5487eb5c86ab98b5e1ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822c7f7ea0f04e7192db749e283b8c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ffdf4339694b4ea85291e87ba0bf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31b598d190243758dc699df634599f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710dd9e04ac540ad82596fdc9bfa324e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2899b6144dd241d9b2e5720775f86539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.13389921e-02 -2.08391920e-02  3.78195606e-02 -1.00276507e-02\n",
      "  -2.18986794e-02  6.64146384e-03 -4.42283042e-02  4.97135855e-02\n",
      "   2.80648302e-02  1.45602329e-02  2.62471903e-02  8.02669004e-02\n",
      "   4.97584650e-03  8.78880396e-02  4.61269952e-02  3.79769392e-02\n",
      "   3.22095715e-02  1.52603211e-02 -4.78855968e-02 -8.71268809e-02\n",
      "   1.09329313e-01  8.22059587e-02  1.47923548e-02 -5.11702560e-02\n",
      "   5.15240170e-02  6.55859634e-02 -5.36913201e-02 -4.96964008e-02\n",
      "   3.65458913e-02 -9.47064720e-03 -4.13955897e-02  5.72569184e-02\n",
      "  -6.83492273e-02  5.84684983e-02 -6.26849830e-02  7.58528113e-02\n",
      "   1.44350184e-02  1.83785819e-02  1.41708171e-02 -5.39689362e-02\n",
      "  -3.47520895e-02 -1.90682001e-02  1.80511866e-02 -2.25276593e-02\n",
      "   4.55970503e-02 -3.47322859e-02 -2.73608770e-02 -1.98490396e-02\n",
      "  -8.14916857e-04 -2.79270671e-02 -3.95562649e-02 -5.84855229e-02\n",
      "   5.34983575e-02  1.18243881e-01 -1.34977931e-02  2.81568654e-02\n",
      "   8.00179224e-03 -5.52489087e-02  1.07748033e-02 -8.26784372e-02\n",
      "  -7.50691667e-02 -7.26926199e-04 -1.14284661e-02 -3.15912664e-02\n",
      "  -2.56439988e-02 -8.93283077e-03  2.13976968e-02 -1.95717043e-03\n",
      "  -3.98999192e-02  1.71870254e-02 -9.86917391e-02  4.32079732e-02\n",
      "   2.14145537e-02  7.41939992e-02  8.17541033e-02  1.30179683e-02\n",
      "   3.96499820e-02 -1.12352595e-01  1.61440372e-02 -4.75933291e-02\n",
      "   7.10801482e-02 -2.49396153e-02 -1.67710036e-02  1.02371067e-01\n",
      "   6.00531697e-02 -3.79600115e-02 -8.91830423e-04 -1.67397764e-02\n",
      "  -8.11639205e-02 -2.96587055e-03 -8.68672207e-02 -9.48272943e-02\n",
      "   8.75561610e-02  7.51264393e-03 -4.40817140e-02  2.50664372e-02\n",
      "  -4.81076129e-02 -7.26852566e-02  4.49803006e-03  3.30109559e-02\n",
      "  -9.52917617e-03 -2.88514476e-02  2.91740876e-02 -9.59848985e-02\n",
      "  -1.13295600e-01 -7.04405904e-02 -1.06133539e-02  1.11098019e-02\n",
      "  -3.91733600e-03 -4.05783094e-02  3.17186676e-02 -2.89384611e-02\n",
      "  -1.91742871e-02 -4.31947932e-02  6.17150143e-02 -8.93389210e-02\n",
      "   8.42685904e-03 -1.18960841e-02 -2.79277209e-02  3.27752195e-02\n",
      "   1.35773560e-02  7.54369274e-02 -4.16411385e-02  7.63626620e-02\n",
      "   2.60961708e-02 -3.30173410e-02  9.69682410e-02 -2.01159814e-33\n",
      "   8.41612089e-03  9.49250385e-02  4.12811041e-02  3.72696482e-02\n",
      "  -9.30487271e-03  3.43330042e-03 -2.14503799e-02  5.93383126e-02\n",
      "  -3.82257178e-02 -3.54571221e-03 -5.11288792e-02  8.00575539e-02\n",
      "  -1.72844883e-02 -1.36364007e-03 -1.50901545e-02 -6.47914335e-02\n",
      "  -3.30008715e-02  4.24927808e-02 -3.90296876e-02  3.09746135e-02\n",
      "  -6.61241356e-03  4.67417687e-02  3.62695381e-02 -2.47308537e-02\n",
      "  -3.20474058e-02 -3.44662182e-03 -1.98131264e-03 -6.16287030e-02\n",
      "   4.73358184e-02 -1.84988491e-02 -3.48375477e-02  5.97698130e-02\n",
      "  -5.21448813e-02  2.64986344e-02  5.34056593e-03  2.45022774e-03\n",
      "  -2.50871684e-02 -9.50678289e-02 -1.16135664e-02 -1.79991592e-02\n",
      "  -2.73288004e-02  5.74762300e-02 -1.10659637e-01  7.15817092e-03\n",
      "   7.70750195e-02  7.02132434e-02  2.04947707e-03 -4.28030677e-02\n",
      "   2.79471707e-02  1.98837183e-03  3.78897004e-02  5.34533933e-02\n",
      "  -5.07847480e-02  1.97708793e-03  1.83810994e-01 -7.26303179e-03\n",
      "   3.04948557e-02 -4.95861657e-03  1.00949377e-01  2.92117912e-02\n",
      "  -1.23772621e-02  3.00229453e-02  1.59176886e-02 -3.04648485e-02\n",
      "   4.33325991e-02 -2.02232972e-02  5.77009693e-02 -3.25590675e-03\n",
      "  -3.42549494e-04 -1.16551397e-02 -2.14824770e-02 -3.31575945e-02\n",
      "  -8.43191636e-04 -3.40885818e-02  1.86595116e-02  1.45057766e-02\n",
      "   2.44679675e-03 -4.46445011e-02  4.31090705e-02  5.86922020e-02\n",
      "  -4.85015176e-02 -1.19012080e-01  2.97994148e-02 -4.78464663e-02\n",
      "   2.59547401e-02 -4.82602753e-02 -3.18483822e-02 -9.71545726e-02\n",
      "   4.57096566e-03 -9.06090811e-03 -8.83249159e-04  2.50313710e-02\n",
      "  -2.26742085e-02  4.16879449e-03  5.73513517e-03  9.56815025e-34\n",
      "  -3.73278745e-02 -1.25535922e-02 -1.03082262e-01  9.87608284e-02\n",
      "  -2.94563267e-02 -1.43612931e-02 -3.82837132e-02  2.79908050e-02\n",
      "   2.47576647e-02  5.60509302e-02 -8.17172509e-03 -3.16256806e-02\n",
      "  -3.93590480e-02 -2.18429063e-02  1.09794021e-01 -6.70883954e-02\n",
      "   4.63268124e-02 -1.40530374e-02  4.11659330e-02  8.68671983e-02\n",
      "   1.58836376e-02  1.58808157e-01 -1.29776880e-01  4.66320962e-02\n",
      "  -9.48794931e-03  6.40925020e-02 -1.15770929e-01  7.14268023e-03\n",
      "   1.17837675e-02  9.03239474e-03 -4.31012586e-02 -1.03710489e-02\n",
      "  -1.86151378e-02 -2.15607714e-02 -5.08089736e-02 -1.17473686e-02\n",
      "  -2.72202920e-02 -1.23246973e-02 -2.62996182e-02  1.65909380e-02\n",
      "   3.03094387e-02  3.99106145e-02 -2.81111021e-02  2.47760974e-02\n",
      "  -9.52601582e-02 -6.82688728e-02 -3.33690681e-02 -4.25384231e-02\n",
      "  -2.54374626e-03  7.71383643e-02 -3.54083776e-02  1.09947287e-02\n",
      "  -1.12818196e-01 -1.21028453e-01 -1.52590368e-02 -5.44914268e-02\n",
      "   5.40056154e-02 -1.03101224e-01  2.88094543e-02 -1.97711978e-02\n",
      "  -9.30150747e-02  2.82325149e-02  8.50701556e-02 -5.99852465e-02\n",
      "   2.28141919e-02 -3.07086948e-02  1.59087908e-02 -2.78398916e-02\n",
      "  -2.87898607e-03 -2.72179022e-02  6.62282705e-02  3.70688662e-02\n",
      "   2.64303144e-02 -3.94684598e-02 -1.07483352e-02 -1.19047686e-02\n",
      "   4.18200605e-02  7.88506120e-03 -2.53780410e-02 -6.98991865e-02\n",
      "   3.05061899e-02  8.73474497e-03  5.21765128e-02  2.98741460e-02\n",
      "   1.51348496e-02  8.98343027e-02 -1.84008647e-02  1.12338969e-03\n",
      "   3.24808918e-02  6.21275902e-02 -3.42305712e-02  3.46833877e-02\n",
      "   2.67563537e-02  1.13286510e-01  1.31214401e-02 -1.58217208e-08\n",
      "  -5.14110848e-02  5.96944354e-02 -3.73664163e-02 -1.06354915e-02\n",
      "  -1.42139504e-02 -4.84035648e-02  3.31888087e-02  8.29870105e-02\n",
      "  -3.32707390e-02 -3.35284829e-04  9.80553180e-02 -4.55461442e-02\n",
      "   9.90805402e-03  4.91861105e-02  1.17603980e-01  1.87714286e-02\n",
      "   7.86552578e-02 -6.34167762e-03 -3.67030427e-02  8.07175133e-03\n",
      "  -8.98550381e-04  8.72058272e-02 -5.00192605e-02  8.99782032e-03\n",
      "  -2.44703423e-02  2.10707299e-02 -3.14435922e-02 -4.93638627e-02\n",
      "   2.44295057e-02 -1.39967278e-02  3.58098163e-03  4.92439196e-02\n",
      "  -2.20062993e-02  4.35395353e-02  5.47413379e-02  2.43604667e-02\n",
      "   7.40203410e-02 -7.40141049e-02 -1.90981887e-02 -3.42055298e-02\n",
      "   7.88777247e-02  7.65522420e-02 -9.69668478e-02  3.22016813e-02\n",
      "   4.90539521e-02 -2.78661377e-03  4.22286727e-02 -1.70268372e-01\n",
      "  -3.40080746e-02  3.91165912e-03  7.40145519e-03 -2.76136827e-02\n",
      "  -4.57474180e-02  2.54089739e-02  7.90525675e-02  3.73700447e-02\n",
      "   4.22542579e-02 -7.54245594e-02 -5.92881739e-02  7.13606700e-02\n",
      "   1.18065067e-02  7.82025158e-02  1.94492359e-02  4.77531888e-02]\n",
      " [-3.65061709e-03 -4.02566232e-02  5.37925847e-02  1.87592637e-02\n",
      "   4.36548814e-02  1.07265860e-01  1.37052145e-02  5.64765893e-02\n",
      "   3.83178182e-02 -3.81296314e-02  4.78521958e-02  4.42149304e-02\n",
      "   2.23990530e-02  6.06395677e-02  2.15431340e-02  3.58680114e-02\n",
      "   8.68860185e-02  9.80533063e-02 -7.73597136e-02 -8.74792635e-02\n",
      "  -4.10939790e-02  2.51762923e-02  6.71608374e-02 -6.30397052e-02\n",
      "   7.63510726e-03 -9.63680819e-03 -6.72210529e-02  3.96240503e-03\n",
      "   6.95275813e-02  2.14077327e-02 -2.73869163e-03 -4.66550793e-03\n",
      "  -2.08296571e-02  2.78403442e-02 -1.73364542e-02  2.82478742e-02\n",
      "   4.42461669e-02  1.06463172e-01 -4.13178839e-02 -2.04074476e-02\n",
      "   8.36504437e-03  2.78143436e-02  5.13444170e-02  6.12559654e-02\n",
      "   5.86420223e-02 -5.18060476e-02 -6.59484789e-02 -2.18247361e-02\n",
      "  -4.19921502e-02  4.15930413e-02 -6.09701835e-02 -2.82707568e-02\n",
      "  -3.88227478e-02  2.98456140e-02  2.10315455e-02 -6.47071935e-03\n",
      "  -3.32621075e-02 -1.17579149e-02  1.10785719e-02 -9.81175154e-02\n",
      "   1.67630222e-02 -5.59938736e-02 -3.41848694e-02  4.53319252e-02\n",
      "   3.42978537e-02 -6.97385613e-03  3.40200542e-03  5.35050295e-02\n",
      "  -5.67048378e-02  1.18010826e-01 -3.72043662e-02  2.63291076e-02\n",
      "  -8.92801434e-02  3.48124355e-02 -7.75280818e-02  4.94074933e-02\n",
      "   5.68245538e-02 -1.02483340e-01  6.50745481e-02 -2.24783830e-02\n",
      "  -3.21006067e-02 -2.35492047e-02  1.46478275e-02 -1.28409883e-03\n",
      "   1.17351905e-01 -1.12275034e-02  7.39701241e-02 -6.42865896e-02\n",
      "  -6.89552277e-02  2.77737007e-02  8.26350786e-03 -7.05972388e-02\n",
      "   4.64272238e-02 -6.82024937e-03  9.92723648e-03 -1.55898537e-02\n",
      "  -3.29161845e-02 -2.54919715e-02  1.22037772e-02  6.56327978e-02\n",
      "   3.29815298e-02  2.29997206e-02  7.80922100e-02  3.18651344e-03\n",
      "  -4.98883277e-02 -3.59912068e-02 -2.51076613e-02  1.59666110e-02\n",
      "   3.59947933e-03 -7.74265751e-02 -1.08642422e-01  4.89925556e-02\n",
      "  -2.34071705e-02  1.15038678e-02  5.48987351e-02 -2.53492780e-02\n",
      "   1.77409127e-02 -5.13560362e-02  4.09484580e-02 -1.90766882e-02\n",
      "  -2.71398332e-02  5.08160964e-02 -4.04528975e-02  4.74189781e-02\n",
      "   1.87084191e-02 -7.64883086e-02  1.77136548e-02 -3.10000636e-33\n",
      "  -1.21809226e-02  2.59609688e-02 -1.91357546e-02  6.19516708e-02\n",
      "   9.14468337e-03  1.42611163e-02 -4.55985069e-02  6.13453463e-02\n",
      "  -8.51536542e-02 -3.42709944e-02 -3.82091925e-02  5.97606562e-02\n",
      "   1.83344465e-02  1.04791289e-02  5.01672439e-02  1.86542571e-02\n",
      "  -2.31891535e-02  1.37787582e-02  1.65511214e-03  2.48640534e-02\n",
      "  -5.38349971e-02 -1.85125489e-02 -2.82220053e-03 -3.37436125e-02\n",
      "  -3.69313434e-02 -2.38055326e-02  1.20403022e-01 -6.21039420e-02\n",
      "  -4.12108898e-02  2.42502820e-02 -5.59023321e-02 -3.04966960e-02\n",
      "  -6.82481527e-02 -1.79481246e-02  2.20062141e-03  1.10732978e-02\n",
      "   1.02061778e-03 -3.48261520e-02  1.49891758e-02 -8.75050388e-03\n",
      "  -5.40855760e-03 -2.03850828e-02 -9.91616677e-03  2.04787008e-03\n",
      "   1.04809301e-02  1.72008120e-03 -9.23035387e-03 -3.43419015e-02\n",
      "   1.65516399e-02 -4.56563346e-02  1.09757753e-02  2.34714989e-02\n",
      "  -3.89114278e-03 -1.08842514e-01  1.05601922e-01 -2.06439868e-02\n",
      "  -1.60452370e-02  1.41882962e-02  2.73804553e-02 -4.69093882e-02\n",
      "  -1.50368102e-02  1.98541656e-02  9.58695859e-02 -3.54821309e-02\n",
      "  -3.42407823e-02  7.78523758e-02 -5.04240729e-02 -2.30547134e-02\n",
      "   1.91292129e-02  2.52683479e-02 -6.17241561e-02  3.61112431e-02\n",
      "  -2.04768945e-02 -6.49500545e-03 -4.58281152e-02  6.94495067e-02\n",
      "  -5.43259159e-02 -1.00172460e-01  3.08690239e-02  1.17122814e-01\n",
      "  -3.66333476e-03 -1.84244618e-01  1.39171779e-02 -1.40380654e-02\n",
      "  -3.96210365e-02 -1.41388088e-01  5.43647073e-02 -8.71689096e-02\n",
      "   6.75088242e-02  2.89072618e-02 -1.67964175e-02 -9.78567544e-03\n",
      "  -4.55209203e-02 -1.96132972e-03 -2.68603880e-02  1.68949854e-33\n",
      "  -3.31909694e-02  1.94348712e-02 -6.68849275e-02  6.47821203e-02\n",
      "  -8.55549797e-03  2.43360791e-02 -6.32420406e-02  1.61888022e-02\n",
      "  -2.44753212e-02 -1.50398221e-02 -8.92010108e-02  1.34052010e-02\n",
      "   4.28511836e-02 -4.46366034e-02  2.76253540e-02  5.50352037e-03\n",
      "  -4.14503515e-02  2.03786567e-02 -1.62264016e-02  4.22022529e-02\n",
      "   1.41475478e-03  9.94223207e-02 -5.71460128e-02  7.38420188e-02\n",
      "   4.14965004e-02  8.90614837e-02 -6.04642220e-02 -7.20138326e-02\n",
      "  -1.31157130e-01 -5.55766560e-02 -3.43460590e-02 -4.77558486e-02\n",
      "  -3.85389142e-02 -4.77392301e-02 -5.84640056e-02  3.23132202e-02\n",
      "   7.33683333e-02 -4.08573449e-02 -1.83145385e-02 -3.50779779e-02\n",
      "   5.94206192e-02  5.31809106e-02 -1.55666023e-02  2.80934125e-02\n",
      "  -1.04945870e-02 -1.43888127e-02 -7.55968094e-02 -1.17197633e-02\n",
      "   7.57965446e-02  5.81873469e-02 -4.25755978e-02  3.81851532e-02\n",
      "  -8.37944746e-02 -5.61070181e-02 -1.72014460e-02 -5.63367270e-02\n",
      "   2.60049524e-03 -1.02772869e-01 -1.26566424e-03 -1.56447832e-02\n",
      "  -1.09514169e-01 -3.83283664e-03  3.97503488e-02 -4.62057590e-02\n",
      "   5.93802147e-02 -1.39045283e-01 -3.16912904e-02  6.14067838e-02\n",
      "  -2.19797785e-03 -9.27407891e-02  1.07508162e-02 -3.91484518e-03\n",
      "  -3.00360564e-02  5.58332801e-02 -3.05788144e-02 -2.35125795e-02\n",
      "   3.72293182e-02  1.56597253e-02 -6.71998113e-02 -6.47743940e-02\n",
      "   8.87671635e-02 -7.48190731e-02  6.93876371e-02 -3.46382745e-02\n",
      "   3.34317870e-02  7.62093589e-02  3.34793441e-02 -2.96905870e-03\n",
      "   2.07741167e-02 -8.93889461e-03 -6.33102730e-02 -1.24690933e-02\n",
      "  -1.75032467e-02  1.17574826e-01  3.06493081e-02 -1.57105990e-08\n",
      "  -6.15324564e-02 -2.43087932e-02  5.48808984e-02  3.30633037e-02\n",
      "  -7.56444633e-02 -7.11502060e-02 -2.29836646e-02  6.43548444e-02\n",
      "  -5.09497561e-02 -3.36612179e-03  5.79672903e-02  2.19356306e-02\n",
      "  -6.35054708e-02  1.38764037e-02  4.74086031e-02  4.33154367e-02\n",
      "   5.74718462e-03 -1.79616492e-02 -3.80584900e-03  2.26670038e-02\n",
      "   5.74051253e-02  1.11191213e-01 -6.37345994e-03  4.52824011e-02\n",
      "  -1.78189222e-02  3.89134772e-02  1.69905350e-02  3.40933725e-02\n",
      "   2.54978463e-02  2.16917563e-02  5.06390780e-02  8.18909779e-02\n",
      "  -9.80566535e-03  4.50544339e-03  4.65276428e-02  1.29042029e-01\n",
      "   7.15280026e-02 -1.00725055e-01 -2.45645380e-04 -3.17357504e-03\n",
      "   5.04630096e-02  6.68728128e-02 -8.23084190e-02  3.21189575e-02\n",
      "   1.00300252e-01  4.13455535e-03  2.14019120e-02 -4.83180285e-02\n",
      "  -4.03572656e-02  3.44826817e-03  3.83811854e-02 -5.31095937e-02\n",
      "   5.30550955e-03  1.54014453e-02  3.79170477e-02  3.94546241e-02\n",
      "   3.25820930e-02 -2.72934176e-02 -5.38104307e-03  3.48102450e-02\n",
      "  -9.61132720e-03  1.74200386e-01  3.71564850e-02 -4.88808705e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode a list of sentences\n",
    "sentences = [\"Transformers are amazing for NLP tasks.\", \"Sentence embeddings are useful.\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the sentence embeddings\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4263a-5b09-4c82-9b14-77d8eefc3e3a",
   "metadata": {},
   "source": [
    "## Other Stuff\n",
    "\n",
    "If you are using Jupyter notebook, be sure to install `jupyterlab` and `ipywidgets` with pip.\n",
    "\n",
    "```.bash\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727ee5a-377c-42ed-95f0-01cc268afd01",
   "metadata": {},
   "source": [
    "## Setup Summary -- \n",
    "\n",
    "More notes can be added here but Pytorch, and Stable Baselines 3 are the two main modules.  Extras required from both will come up but should not be a huge issue.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
