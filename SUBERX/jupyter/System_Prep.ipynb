{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f90f37-d975-49cc-9ff8-e118b25232ae",
   "metadata": {},
   "source": [
    "# System Preparation \n",
    "\n",
    "This notebook serves as notes for reference to getting setup to develop with SUBER.\n",
    "\n",
    "- [GPU Preparation](#gpu_prep)\n",
    "- [PyTorch Installation](#torch_install)\n",
    "- [Pytorch Examples]()\n",
    "- [Transformers and Tokenizers]()\n",
    "\n",
    "TODO -- fix links above.\n",
    "\n",
    "## Conda or Python Virtual Environments\n",
    "I switched to ordinary Python virtual environments because Anaconda itself was becoming a chore.  Why would it not simply add the mdodule I wanted?  It would take forever and stall in many cases.  The Python version used for this project is Python 3.10.12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9042aca-73bd-4764-a169-56a8188bd4b9",
   "metadata": {},
   "source": [
    "## <a href=\"gpu_prep\">GPU Preparation</a>\n",
    "\n",
    "GPU and nvcc (aka cuda) versions should be within the same major version. I've noticed that Ubuntu 22.04 loads on some systems have been way out of **alignment**. Try to get them at the same version.\n",
    "\n",
    "\n",
    "```\n",
    "sudo apt-get purge 'nvidia*' 'cuda*'\n",
    "\n",
    "sudo apt-get install nvidia-driver-535\n",
    "\n",
    "sudo reboot\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run\n",
    "\n",
    "chmod a+x cuda_12.2.0_535.54.03_linux.run\n",
    " \n",
    "sudo ./cuda_12.2.0_535.54.03_linux.run # And follow the prompts\n",
    "\n",
    "# Edit your .bashrc and put these in. But don't put the hastags in front of them.\n",
    "# export PATH=/usr/local/cuda-12.2/bin${PATH:+:${PATH}}\n",
    "#export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "\n",
    "\n",
    "# I also had to do this.  If you cannot type nvcc --version then you need to check the permissions.\n",
    "sudo chmod -R 755 /usr/local/cuda-12.2\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The results should be something like this:\n",
    "\n",
    "```\n",
    "acshell@ip-10-114-92-249:~$ nvidia-smi | grep -i \"cuda version\" | awk '{print $9}'\n",
    "12.2\n",
    "acshell@ip-10-114-92-249:~$ nvcc --version\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2023 NVIDIA Corporation\n",
    "Built on Tue_Jun_13_19:16:58_PDT_2023\n",
    "Cuda compilation tools, release 12.2, V12.2.91\n",
    "Build cuda_12.2.r12.2/compiler.32965470_0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7795877-6869-4f73-8b4d-200276e90df9",
   "metadata": {},
   "source": [
    "## <a href=torch_install>Torch Installation<a/>\n",
    "\n",
    "You should do this first. If this doesn't work, nothing will. \n",
    "\n",
    "PyTorch cuda version should be within a minor version of the cuda drivers and cuda drivers need to align with nvidia drivers.  Try hard to make this happen by paying attention to versions.  \n",
    "\n",
    "```.bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed9f27e-d2b1-4613-8d06-c06b088ecca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available? True.\n",
      "Torch Cuda Version is 2.4.1+cu124.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(f\"Is Cuda available? {torch.cuda.is_available()}.\")  # Should return True\n",
    "print(f\"Torch Cuda Version is {torch.__version__}.\")  # Should return '12.1'\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d74b6bd-748d-4de1-9d9f-cd3e453d3781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch can use the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737d4e6d-a533-4b7b-8f43-3063a5e016f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU Device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print(\"Current GPU Device:\", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a3b4e7-7610-448c-8989-f527582c15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu124\n",
      "CUDA is available! PyTorch can use the GPU.\n",
      "Current GPU Device: NVIDIA GeForce RTX 3060\n",
      "Number of GPUs available: 1\n",
      "Current CUDA version: 2.4.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use the GPU.\")\n",
    "    print(\"Current GPU Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA version:\", torch.__version__)\n",
    "else:\n",
    "    print(\"CUDA is NOT available. PyTorch is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4729f-6f5c-4154-9465-ddc6c117b774",
   "metadata": {},
   "source": [
    "### Torch Examples\n",
    "\n",
    "Here are some examples showing that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc3da4c-9a5b-433e-a7f4-c8a2c6fdfb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication on CPU took: 3.4404 seconds\n",
      "Result tensor size on CPU: torch.Size([10000, 10000])\n",
      "Matrix multiplication on GPU took: 0.2793 seconds\n",
      "Result tensor size on GPU: torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the size of the tensors\n",
    "size = 10000\n",
    "\n",
    "# Create two large random tensors for CPU\n",
    "tensor1_cpu = torch.randn(size, size)\n",
    "tensor2_cpu = torch.randn(size, size)\n",
    "\n",
    "# Perform matrix multiplication on the CPU and time it\n",
    "start_time = time.time()\n",
    "result_cpu = torch.matmul(tensor1_cpu, tensor2_cpu)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication on CPU took: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Result tensor size on CPU: {result_cpu.size()}\")\n",
    "\n",
    "# Check if CUDA is available and perform the same test on the GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Create two large random tensors for GPU\n",
    "    tensor1_gpu = tensor1_cpu.to(device)\n",
    "    tensor2_gpu = tensor2_cpu.to(device)\n",
    "\n",
    "    # Perform matrix multiplication on the GPU and time it\n",
    "    torch.cuda.synchronize()  # Ensure all CUDA operations are finished\n",
    "    start_time = time.time()\n",
    "    result_gpu = torch.matmul(tensor1_gpu, tensor2_gpu)\n",
    "    torch.cuda.synchronize()  # Ensure the GPU has finished the computation\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication on GPU took: {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Result tensor size on GPU: {result_gpu.size()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abb85a-a959-4938-b317-4c502d6b3ae4",
   "metadata": {},
   "source": [
    "## Stable Baselines 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fdeb1-9a02-454c-ac38-1f13c102a7be",
   "metadata": {},
   "source": [
    "## Install Stable Baselines 3\n",
    "\n",
    "```\n",
    "pip install stable-baselines3[extra]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6ed398-a51b-42b5-a509-a1fd94599c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses INFO, WARNING, and ERROR messages\n",
    "\n",
    "import stable_baselines3\n",
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2812c9-78a9-44a2-b997-431bc8498d51",
   "metadata": {},
   "source": [
    "### SB3 Example\n",
    "\n",
    "Note, it takes many iteraitons and the proper algorithm to get good results; this just shows it working.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066b6955-d608-4996-9f99-cba81995e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.7     |\n",
      "|    ep_rew_mean     | 22.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 641      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.6        |\n",
      "|    ep_rew_mean          | 25.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009435211 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00251    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.3         |\n",
      "|    ep_rew_mean          | 34.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117816795 |\n",
      "|    clip_fraction        | 0.0868       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.666       |\n",
      "|    explained_variance   | 0.0881       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.13         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 46.5         |\n",
      "|    ep_rew_mean          | 46.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 434          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092919525 |\n",
      "|    clip_fraction        | 0.0828       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.634       |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    value_loss           | 52.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.7        |\n",
      "|    ep_rew_mean          | 59.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 421         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005601862 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "# Create the CartPole-v1 environment with the \"rgb_array\" render mode\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Create the PPO model (you can replace PPO with other algorithms if you want)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the agent for 10,000 steps\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Test the trained agent and render in the notebook\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Set up the plot for dynamic updates\n",
    "#plt.ion()  # Turn on interactive mode for matplotlib\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "\n",
    "    if done or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899a604-34d0-4299-be1c-96aaa804e34c",
   "metadata": {},
   "source": [
    "## Install Transformers and Tokenizers\n",
    "\n",
    "```\n",
    "pip install -U transformers tokenizers\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8825337-4ecb-483b-aff1-f649ee0d4f07",
   "metadata": {},
   "source": [
    "### Transformer and Tokenizer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b96fc0-bb19-4440-88f6-23db75f85940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Transformers are amazing for NLP tasks.\n",
      "Tokenized Input IDs: tensor([[  101, 19081,  2024,  6429,  2005, 17953,  2361,  8518,  1012,   102]])\n",
      "Decoded Text: transformers are amazing for nlp tasks.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',quiet=True)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text\n",
    "text = \"Transformers are amazing for NLP tasks.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get the tokenized input IDs\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# Decode the token IDs back to text\n",
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print original text, tokenized input, and decoded text\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Tokenized Input IDs:\", input_ids)\n",
    "print(\"Decoded Text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af7930-6087-4db5-82f9-ae56de146383",
   "metadata": {},
   "source": [
    "## Sentence Transformers\n",
    "\n",
    "```/bash\n",
    "pip install sentence-transformers\n",
    "\n",
    "```\n",
    "\n",
    "Need this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254201e2-3fb5-4f0f-a346-dfed1abb0264",
   "metadata": {},
   "source": [
    "### Sentence Transformers Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f76f3b-253d-4df7-af11-cac9ee1bd986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75504e5c0e154edcab480eaba389738a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcd037471524f5daa5ed2d807c2cad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7975783c20c44e1ac28790e5c27badc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31d103c29ae45739e813f540679d998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d668dc689e43c680730b41994ce66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e348d2e59844ebb37e0d900410a277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cf2dd365d047ec95da80438e3c8375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60e4655f20d4c038c217dcd6a1809c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871c5114aa5640d0b0ca5a01b145f5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22efa34cfb0b40a1b558865cdea8dbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80774c4e90284dac95b63e524d9d336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.13389996e-02 -2.08391845e-02  3.78195457e-02 -1.00276396e-02\n",
      "  -2.18986850e-02  6.64145267e-03 -4.42283228e-02  4.97136004e-02\n",
      "   2.80648097e-02  1.45602487e-02  2.62472015e-02  8.02669302e-02\n",
      "   4.97582275e-03  8.78880620e-02  4.61270101e-02  3.79769132e-02\n",
      "   3.22095267e-02  1.52603202e-02 -4.78855893e-02 -8.71268734e-02\n",
      "   1.09329313e-01  8.22059512e-02  1.47923781e-02 -5.11702783e-02\n",
      "   5.15240207e-02  6.55859411e-02 -5.36912866e-02 -4.96964231e-02\n",
      "   3.65458727e-02 -9.47063975e-03 -4.13955748e-02  5.72569184e-02\n",
      "  -6.83491975e-02  5.84684983e-02 -6.26850128e-02  7.58528337e-02\n",
      "   1.44350342e-02  1.83785968e-02  1.41708506e-02 -5.39689213e-02\n",
      "  -3.47521193e-02 -1.90682057e-02  1.80511903e-02 -2.25276574e-02\n",
      "   4.55970578e-02 -3.47322933e-02 -2.73609236e-02 -1.98490974e-02\n",
      "  -8.14881001e-04 -2.79271007e-02 -3.95562686e-02 -5.84855005e-02\n",
      "   5.34983575e-02  1.18243881e-01 -1.34977708e-02  2.81568468e-02\n",
      "   8.00179783e-03 -5.52489236e-02  1.07748099e-02 -8.26784223e-02\n",
      "  -7.50691742e-02 -7.26942264e-04 -1.14284456e-02 -3.15912627e-02\n",
      "  -2.56439988e-02 -8.93283263e-03  2.13977061e-02 -1.95717951e-03\n",
      "  -3.98999229e-02  1.71870161e-02 -9.86917391e-02  4.32079621e-02\n",
      "   2.14145463e-02  7.41940066e-02  8.17540735e-02  1.30180316e-02\n",
      "   3.96499671e-02 -1.12352587e-01  1.61440168e-02 -4.75933291e-02\n",
      "   7.10801706e-02 -2.49395855e-02 -1.67709831e-02  1.02371052e-01\n",
      "   6.00531772e-02 -3.79599780e-02 -8.91844684e-04 -1.67397819e-02\n",
      "  -8.11639279e-02 -2.96587590e-03 -8.68672282e-02 -9.48273316e-02\n",
      "   8.75561610e-02  7.51265045e-03 -4.40817028e-02  2.50664745e-02\n",
      "  -4.81076017e-02 -7.26852566e-02  4.49801935e-03  3.30109671e-02\n",
      "  -9.52915382e-03 -2.88514495e-02  2.91741081e-02 -9.59849209e-02\n",
      "  -1.13295607e-01 -7.04405755e-02 -1.06133530e-02  1.11097982e-02\n",
      "  -3.91733227e-03 -4.05783318e-02  3.17186750e-02 -2.89384406e-02\n",
      "  -1.91743094e-02 -4.31948192e-02  6.17149957e-02 -8.93389136e-02\n",
      "   8.42685625e-03 -1.18960775e-02 -2.79276762e-02  3.27752419e-02\n",
      "   1.35773970e-02  7.54369274e-02 -4.16411497e-02  7.63626918e-02\n",
      "   2.60962229e-02 -3.30173597e-02  9.69682336e-02 -2.01159777e-33\n",
      "   8.41610972e-03  9.49250236e-02  4.12810817e-02  3.72696444e-02\n",
      "  -9.30491183e-03  3.43328109e-03 -2.14503836e-02  5.93383312e-02\n",
      "  -3.82257141e-02 -3.54571594e-03 -5.11288792e-02  8.00575688e-02\n",
      "  -1.72845125e-02 -1.36363774e-03 -1.50901787e-02 -6.47913963e-02\n",
      "  -3.30008902e-02  4.24927920e-02 -3.90296988e-02  3.09746377e-02\n",
      "  -6.61239307e-03  4.67417091e-02  3.62695418e-02 -2.47308500e-02\n",
      "  -3.20473835e-02 -3.44662019e-03 -1.98130170e-03 -6.16286807e-02\n",
      "   4.73358147e-02 -1.84988342e-02 -3.48375365e-02  5.97697906e-02\n",
      "  -5.21448962e-02  2.64986325e-02  5.34055009e-03  2.45023286e-03\n",
      "  -2.50871740e-02 -9.50678065e-02 -1.16135571e-02 -1.79991703e-02\n",
      "  -2.73287948e-02  5.74762598e-02 -1.10659629e-01  7.15816813e-03\n",
      "   7.70750120e-02  7.02132508e-02  2.04946916e-03 -4.28030565e-02\n",
      "   2.79472042e-02  1.98841561e-03  3.78897078e-02  5.34534007e-02\n",
      "  -5.07847518e-02  1.97706511e-03  1.83811009e-01 -7.26303039e-03\n",
      "   3.04948520e-02 -4.95861657e-03  1.00949399e-01  2.92117950e-02\n",
      "  -1.23772491e-02  3.00229322e-02  1.59176588e-02 -3.04648448e-02\n",
      "   4.33325917e-02 -2.02232916e-02  5.77009656e-02 -3.25589045e-03\n",
      "  -3.42560495e-04 -1.16551146e-02 -2.14824900e-02 -3.31575982e-02\n",
      "  -8.43159738e-04 -3.40885781e-02  1.86595283e-02  1.45057533e-02\n",
      "   2.44680303e-03 -4.46444936e-02  4.31090705e-02  5.86921871e-02\n",
      "  -4.85014915e-02 -1.19012050e-01  2.97994222e-02 -4.78464775e-02\n",
      "   2.59547420e-02 -4.82602529e-02 -3.18483673e-02 -9.71545801e-02\n",
      "   4.57091955e-03 -9.06090904e-03 -8.83210800e-04  2.50313953e-02\n",
      "  -2.26742364e-02  4.16880054e-03  5.73512586e-03  9.56814933e-34\n",
      "  -3.73278558e-02 -1.25535903e-02 -1.03082314e-01  9.87608060e-02\n",
      "  -2.94563398e-02 -1.43612605e-02 -3.82837281e-02  2.79907733e-02\n",
      "   2.47576758e-02  5.60509153e-02 -8.17171112e-03 -3.16256844e-02\n",
      "  -3.93590704e-02 -2.18429342e-02  1.09793991e-01 -6.70884028e-02\n",
      "   4.63267826e-02 -1.40530430e-02  4.11659032e-02  8.68671983e-02\n",
      "   1.58836413e-02  1.58808187e-01 -1.29776880e-01  4.66320850e-02\n",
      "  -9.48795862e-03  6.40924871e-02 -1.15770958e-01  7.14267557e-03\n",
      "   1.17837284e-02  9.03236587e-03 -4.31012772e-02 -1.03710275e-02\n",
      "  -1.86151490e-02 -2.15607956e-02 -5.08089438e-02 -1.17473789e-02\n",
      "  -2.72202920e-02 -1.23247067e-02 -2.62996107e-02  1.65909715e-02\n",
      "   3.03094834e-02  3.99106182e-02 -2.81110648e-02  2.47760955e-02\n",
      "  -9.52601805e-02 -6.82688728e-02 -3.33690979e-02 -4.25384194e-02\n",
      "  -2.54374440e-03  7.71384090e-02 -3.54083627e-02  1.09947519e-02\n",
      "  -1.12818249e-01 -1.21028453e-01 -1.52590442e-02 -5.44914305e-02\n",
      "   5.40056042e-02 -1.03101231e-01  2.88094357e-02 -1.97712034e-02\n",
      "  -9.30150971e-02  2.82325298e-02  8.50701630e-02 -5.99852353e-02\n",
      "   2.28141788e-02 -3.07087079e-02  1.59088038e-02 -2.78399028e-02\n",
      "  -2.87897233e-03 -2.72179097e-02  6.62282854e-02  3.70688327e-02\n",
      "   2.64303163e-02 -3.94684635e-02 -1.07483650e-02 -1.19048087e-02\n",
      "   4.18200493e-02  7.88504351e-03 -2.53780335e-02 -6.98991567e-02\n",
      "   3.05061974e-02  8.73475708e-03  5.21764718e-02  2.98741348e-02\n",
      "   1.51348887e-02  8.98343101e-02 -1.84008721e-02  1.12339680e-03\n",
      "   3.24808583e-02  6.21275902e-02 -3.42305787e-02  3.46834064e-02\n",
      "   2.67563406e-02  1.13286510e-01  1.31214364e-02 -1.58217208e-08\n",
      "  -5.14110997e-02  5.96944354e-02 -3.73664536e-02 -1.06354523e-02\n",
      "  -1.42139476e-02 -4.84035574e-02  3.31887975e-02  8.29870477e-02\n",
      "  -3.32707390e-02 -3.35251854e-04  9.80553478e-02 -4.55461368e-02\n",
      "   9.90804937e-03  4.91860993e-02  1.17604010e-01  1.87714472e-02\n",
      "   7.86552578e-02 -6.34167157e-03 -3.67030613e-02  8.07174202e-03\n",
      "  -8.98554455e-04  8.72058123e-02 -5.00192717e-02  8.99784826e-03\n",
      "  -2.44703349e-02  2.10707486e-02 -3.14435847e-02 -4.93638366e-02\n",
      "   2.44295169e-02 -1.39967455e-02  3.58096301e-03  4.92439121e-02\n",
      "  -2.20063291e-02  4.35395353e-02  5.47413528e-02  2.43605003e-02\n",
      "   7.40203559e-02 -7.40141049e-02 -1.90981664e-02 -3.42055336e-02\n",
      "   7.88777098e-02  7.65522346e-02 -9.69668478e-02  3.22016962e-02\n",
      "   4.90539260e-02 -2.78660748e-03  4.22286391e-02 -1.70268312e-01\n",
      "  -3.40080634e-02  3.91164608e-03  7.40142865e-03 -2.76136957e-02\n",
      "  -4.57474291e-02  2.54089702e-02  7.90525302e-02  3.73700745e-02\n",
      "   4.22542766e-02 -7.54245892e-02 -5.92881814e-02  7.13606775e-02\n",
      "   1.18064992e-02  7.82025307e-02  1.94492210e-02  4.77532074e-02]\n",
      " [-3.65064410e-03 -4.02566306e-02  5.37926257e-02  1.87592395e-02\n",
      "   4.36549075e-02  1.07265837e-01  1.37052219e-02  5.64765893e-02\n",
      "   3.83178778e-02 -3.81296203e-02  4.78521697e-02  4.42149602e-02\n",
      "   2.23990455e-02  6.06395490e-02  2.15431638e-02  3.58680151e-02\n",
      "   8.68859962e-02  9.80533138e-02 -7.73597509e-02 -8.74792337e-02\n",
      "  -4.10939865e-02  2.51762737e-02  6.71608225e-02 -6.30397052e-02\n",
      "   7.63511751e-03 -9.63678304e-03 -6.72210157e-02  3.96242831e-03\n",
      "   6.95275366e-02  2.14077123e-02 -2.73867277e-03 -4.66554752e-03\n",
      "  -2.08296627e-02  2.78403144e-02 -1.73364505e-02  2.82478668e-02\n",
      "   4.42461520e-02  1.06463164e-01 -4.13178541e-02 -2.04074625e-02\n",
      "   8.36503692e-03  2.78143231e-02  5.13444021e-02  6.12559691e-02\n",
      "   5.86420372e-02 -5.18060550e-02 -6.59484640e-02 -2.18247641e-02\n",
      "  -4.19921502e-02  4.15930226e-02 -6.09701686e-02 -2.82707866e-02\n",
      "  -3.88228036e-02  2.98456009e-02  2.10315455e-02 -6.47072168e-03\n",
      "  -3.32620740e-02 -1.17579428e-02  1.10785402e-02 -9.81175154e-02\n",
      "   1.67630296e-02 -5.59938662e-02 -3.41848359e-02  4.53318991e-02\n",
      "   3.42978761e-02 -6.97385613e-03  3.40200192e-03  5.35050184e-02\n",
      "  -5.67048416e-02  1.18010879e-01 -3.72043289e-02  2.63291039e-02\n",
      "  -8.92801434e-02  3.48124132e-02 -7.75280967e-02  4.94074933e-02\n",
      "   5.68245836e-02 -1.02483340e-01  6.50745705e-02 -2.24783476e-02\n",
      "  -3.21005993e-02 -2.35492159e-02  1.46478629e-02 -1.28407404e-03\n",
      "   1.17351927e-01 -1.12275146e-02  7.39701241e-02 -6.42865896e-02\n",
      "  -6.89552203e-02  2.77737118e-02  8.26348085e-03 -7.05972463e-02\n",
      "   4.64271903e-02 -6.82026008e-03  9.92726441e-03 -1.55898798e-02\n",
      "  -3.29161659e-02 -2.54919641e-02  1.22037455e-02  6.56328425e-02\n",
      "   3.29815373e-02  2.29997300e-02  7.80921951e-02  3.18648294e-03\n",
      "  -4.98883389e-02 -3.59911956e-02 -2.51076631e-02  1.59666128e-02\n",
      "   3.59946373e-03 -7.74266049e-02 -1.08642422e-01  4.89925444e-02\n",
      "  -2.34071855e-02  1.15039041e-02  5.48987389e-02 -2.53492910e-02\n",
      "   1.77409165e-02 -5.13560139e-02  4.09484804e-02 -1.90766901e-02\n",
      "  -2.71398444e-02  5.08160889e-02 -4.04529087e-02  4.74189632e-02\n",
      "   1.87084451e-02 -7.64882714e-02  1.77136473e-02 -3.10000819e-33\n",
      "  -1.21809337e-02  2.59609390e-02 -1.91357639e-02  6.19516559e-02\n",
      "   9.14470572e-03  1.42611228e-02 -4.55985032e-02  6.13453314e-02\n",
      "  -8.51536319e-02 -3.42710018e-02 -3.82091962e-02  5.97606599e-02\n",
      "   1.83344670e-02  1.04790796e-02  5.01671880e-02  1.86542869e-02\n",
      "  -2.31891461e-02  1.37787620e-02  1.65510585e-03  2.48640683e-02\n",
      "  -5.38350232e-02 -1.85125880e-02 -2.82222778e-03 -3.37436087e-02\n",
      "  -3.69313657e-02 -2.38055643e-02  1.20402999e-01 -6.21039942e-02\n",
      "  -4.12108935e-02  2.42502932e-02 -5.59023358e-02 -3.04966811e-02\n",
      "  -6.82481676e-02 -1.79481562e-02  2.20057904e-03  1.10732801e-02\n",
      "   1.02061778e-03 -3.48261446e-02  1.49891758e-02 -8.75051040e-03\n",
      "  -5.40851429e-03 -2.03850903e-02 -9.91614256e-03  2.04787566e-03\n",
      "   1.04809171e-02  1.72010111e-03 -9.23037156e-03 -3.43419015e-02\n",
      "   1.65516660e-02 -4.56563570e-02  1.09757800e-02  2.34714970e-02\n",
      "  -3.89115652e-03 -1.08842544e-01  1.05601951e-01 -2.06440054e-02\n",
      "  -1.60452481e-02  1.41883306e-02  2.73804311e-02 -4.69093882e-02\n",
      "  -1.50368335e-02  1.98541563e-02  9.58696008e-02 -3.54821421e-02\n",
      "  -3.42407562e-02  7.78523833e-02 -5.04240654e-02 -2.30546817e-02\n",
      "   1.91291887e-02  2.52683442e-02 -6.17241785e-02  3.61112356e-02\n",
      "  -2.04769019e-02 -6.49500173e-03 -4.58281115e-02  6.94494918e-02\n",
      "  -5.43259308e-02 -1.00172475e-01  3.08690183e-02  1.17122784e-01\n",
      "  -3.66333243e-03 -1.84244573e-01  1.39171779e-02 -1.40380887e-02\n",
      "  -3.96209918e-02 -1.41388059e-01  5.43646999e-02 -8.71689096e-02\n",
      "   6.75088465e-02  2.89072804e-02 -1.67964119e-02 -9.78565589e-03\n",
      "  -4.55209389e-02 -1.96133135e-03 -2.68604178e-02  1.68949928e-33\n",
      "  -3.31909321e-02  1.94348749e-02 -6.68848976e-02  6.47820905e-02\n",
      "  -8.55551753e-03  2.43361071e-02 -6.32420555e-02  1.61887985e-02\n",
      "  -2.44753528e-02 -1.50398165e-02 -8.92010406e-02  1.34052169e-02\n",
      "   4.28511538e-02 -4.46366332e-02  2.76253317e-02  5.50351851e-03\n",
      "  -4.14503813e-02  2.03786418e-02 -1.62264295e-02  4.22022194e-02\n",
      "   1.41474372e-03  9.94222909e-02 -5.71459830e-02  7.38419965e-02\n",
      "   4.14964519e-02  8.90614912e-02 -6.04641922e-02 -7.20138550e-02\n",
      "  -1.31157175e-01 -5.55766635e-02 -3.43460962e-02 -4.77558561e-02\n",
      "  -3.85388993e-02 -4.77392301e-02 -5.84639907e-02  3.23132165e-02\n",
      "   7.33683035e-02 -4.08573709e-02 -1.83145478e-02 -3.50779779e-02\n",
      "   5.94206341e-02  5.31809330e-02 -1.55666089e-02  2.80934498e-02\n",
      "  -1.04945749e-02 -1.43888379e-02 -7.55968094e-02 -1.17197456e-02\n",
      "   7.57965147e-02  5.81873581e-02 -4.25755978e-02  3.81851085e-02\n",
      "  -8.37944970e-02 -5.61070405e-02 -1.72014255e-02 -5.63367158e-02\n",
      "   2.60047847e-03 -1.02772847e-01 -1.26566750e-03 -1.56447664e-02\n",
      "  -1.09514177e-01 -3.83283990e-03  3.97503190e-02 -4.62057665e-02\n",
      "   5.93802258e-02 -1.39045298e-01 -3.16912606e-02  6.14067912e-02\n",
      "  -2.19795154e-03 -9.27408263e-02  1.07508609e-02 -3.91482515e-03\n",
      "  -3.00360937e-02  5.58332764e-02 -3.05787791e-02 -2.35125814e-02\n",
      "   3.72293219e-02  1.56597085e-02 -6.71998113e-02 -6.47743940e-02\n",
      "   8.87671411e-02 -7.48190582e-02  6.93876371e-02 -3.46382782e-02\n",
      "   3.34317610e-02  7.62093514e-02  3.34793516e-02 -2.96906242e-03\n",
      "   2.07741242e-02 -8.93892907e-03 -6.33102804e-02 -1.24690533e-02\n",
      "  -1.75032411e-02  1.17574841e-01  3.06493230e-02 -1.57105990e-08\n",
      "  -6.15324192e-02 -2.43087560e-02  5.48808761e-02  3.30632962e-02\n",
      "  -7.56444409e-02 -7.11501911e-02 -2.29836572e-02  6.43548295e-02\n",
      "  -5.09497486e-02 -3.36610526e-03  5.79673238e-02  2.19356027e-02\n",
      "  -6.35054857e-02  1.38764335e-02  4.74085920e-02  4.33154143e-02\n",
      "   5.74720884e-03 -1.79616343e-02 -3.80585971e-03  2.26670224e-02\n",
      "   5.74051291e-02  1.11191243e-01 -6.37345063e-03  4.52824347e-02\n",
      "  -1.78189185e-02  3.89134772e-02  1.69905704e-02  3.40933427e-02\n",
      "   2.54978351e-02  2.16917600e-02  5.06390855e-02  8.18909928e-02\n",
      "  -9.80567094e-03  4.50543687e-03  4.65276428e-02  1.29042014e-01\n",
      "   7.15279877e-02 -1.00725055e-01 -2.45631469e-04 -3.17353080e-03\n",
      "   5.04630357e-02  6.68727979e-02 -8.23083967e-02  3.21189389e-02\n",
      "   1.00300275e-01  4.13459307e-03  2.14019027e-02 -4.83179986e-02\n",
      "  -4.03572917e-02  3.44824931e-03  3.83811817e-02 -5.31095713e-02\n",
      "   5.30552026e-03  1.54014556e-02  3.79170477e-02  3.94546315e-02\n",
      "   3.25820930e-02 -2.72934120e-02 -5.38103748e-03  3.48102450e-02\n",
      "  -9.61133931e-03  1.74200416e-01  3.71564664e-02 -4.88810660e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode a list of sentences\n",
    "sentences = [\"Transformers are amazing for NLP tasks.\", \"Sentence embeddings are useful.\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the sentence embeddings\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4263a-5b09-4c82-9b14-77d8eefc3e3a",
   "metadata": {},
   "source": [
    "## Other Stuff\n",
    "\n",
    "If you are using Jupyter notebook, be sure to install `jupyterlab` and `ipywidgets` with pip.\n",
    "\n",
    "```.bash\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8975939-dfa8-4f6a-8835-08377eae50b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3727ee5a-377c-42ed-95f0-01cc268afd01",
   "metadata": {},
   "source": [
    "## Setup Summary -- \n",
    "\n",
    "More notes can be added here but Pytorch, and Stable Baselines 3 are the two main modules.  Extras required from both will come up but should not be a huge issue.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
