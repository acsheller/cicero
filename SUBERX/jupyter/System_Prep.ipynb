{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f90f37-d975-49cc-9ff8-e118b25232ae",
   "metadata": {},
   "source": [
    "# System Preparation \n",
    "\n",
    "This notebook serves as notes for reference to getting setup to develop with SUBER.\n",
    "\n",
    "- [GPU Preparation](#gpu_prep)\n",
    "- [PyTorch Installation](#torch_install)\n",
    "- [Pytorch Examples]()\n",
    "- [Transformers and Tokenizers]()\n",
    "\n",
    "TODO -- fix links above.\n",
    "\n",
    "## Conda or Python Virtual Environments\n",
    "I switched to ordinary Python virtual environments because Anaconda itself was becoming a chore.  Why would it not simply add the mdodule I wanted?  It would take forever and stall in many cases.  The Python version used for this project is Python 3.10.12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9042aca-73bd-4764-a169-56a8188bd4b9",
   "metadata": {},
   "source": [
    "## <a href=\"gpu_prep\">GPU Preparation</a>\n",
    "\n",
    "GPU and nvcc (aka cuda) versions should be within the same major version. I've noticed that Ubuntu 22.04 loads on some systems have been way out of **alignment**. Try to get them at the same version.\n",
    "\n",
    "\n",
    "```\n",
    "sudo apt-get purge 'nvidia*' 'cuda*'\n",
    "\n",
    "sudo apt-get install nvidia-driver-535\n",
    "\n",
    "sudo reboot\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run\n",
    "\n",
    "chmod a+x cuda_12.2.0_535.54.03_linux.run\n",
    " \n",
    "sudo ./cuda_12.2.0_535.54.03_linux.run # And follow the prompts\n",
    "\n",
    "# Edit your .bashrc and put these in. But don't put the hastags in front of them.\n",
    "# export PATH=/usr/local/cuda-12.2/bin${PATH:+:${PATH}}\n",
    "#export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "\n",
    "\n",
    "# I also had to do this.  If you cannot type nvcc --version then you need to check the permissions.\n",
    "sudo chmod -R 755 /usr/local/cuda-12.2\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "The results should be something like this:\n",
    "\n",
    "```\n",
    "acshell@ip-10-114-92-249:~$ nvidia-smi | grep -i \"cuda version\" | awk '{print $9}'\n",
    "12.2\n",
    "acshell@ip-10-114-92-249:~$ nvcc --version\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2023 NVIDIA Corporation\n",
    "Built on Tue_Jun_13_19:16:58_PDT_2023\n",
    "Cuda compilation tools, release 12.2, V12.2.91\n",
    "Build cuda_12.2.r12.2/compiler.32965470_0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7795877-6869-4f73-8b4d-200276e90df9",
   "metadata": {},
   "source": [
    "## <a href=torch_install>Torch Installation<a/>\n",
    "\n",
    "You should do this first. If this doesn't work, nothing will. \n",
    "\n",
    "PyTorch cuda version should be within a minor version of the cuda drivers and cuda drivers need to align with nvidia drivers.  Try hard to make this happen by paying attention to versions.  \n",
    "\n",
    "```.bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed9f27e-d2b1-4613-8d06-c06b088ecca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available? False.\n",
      "Torch Cuda Version is 12.4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(f\"Is Cuda available? {torch.cuda.is_available()}.\")  # Should return True\n",
    "print(f\"Torch Cuda Version is {torch.version.cuda}.\")  # Should return '12.1'\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4729f-6f5c-4154-9465-ddc6c117b774",
   "metadata": {},
   "source": [
    "### Torch Examples\n",
    "\n",
    "Here are some examples showing that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc3da4c-9a5b-433e-a7f4-c8a2c6fdfb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication on CPU took: 3.4662 seconds\n",
      "Result tensor size on CPU: torch.Size([10000, 10000])\n",
      "CUDA is not available on this system.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the size of the tensors\n",
    "size = 10000\n",
    "\n",
    "# Create two large random tensors for CPU\n",
    "tensor1_cpu = torch.randn(size, size)\n",
    "tensor2_cpu = torch.randn(size, size)\n",
    "\n",
    "# Perform matrix multiplication on the CPU and time it\n",
    "start_time = time.time()\n",
    "result_cpu = torch.matmul(tensor1_cpu, tensor2_cpu)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication on CPU took: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Result tensor size on CPU: {result_cpu.size()}\")\n",
    "\n",
    "# Check if CUDA is available and perform the same test on the GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # Create two large random tensors for GPU\n",
    "    tensor1_gpu = tensor1_cpu.to(device)\n",
    "    tensor2_gpu = tensor2_cpu.to(device)\n",
    "\n",
    "    # Perform matrix multiplication on the GPU and time it\n",
    "    torch.cuda.synchronize()  # Ensure all CUDA operations are finished\n",
    "    start_time = time.time()\n",
    "    result_gpu = torch.matmul(tensor1_gpu, tensor2_gpu)\n",
    "    torch.cuda.synchronize()  # Ensure the GPU has finished the computation\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication on GPU took: {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Result tensor size on GPU: {result_gpu.size()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abb85a-a959-4938-b317-4c502d6b3ae4",
   "metadata": {},
   "source": [
    "## Stable Baselines 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fdeb1-9a02-454c-ac38-1f13c102a7be",
   "metadata": {},
   "source": [
    "## Install Stable Baselines 3\n",
    "\n",
    "```\n",
    "pip install stable-baselines3[extra]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6ed398-a51b-42b5-a509-a1fd94599c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses INFO, WARNING, and ERROR messages\n",
    "\n",
    "import stable_baselines3\n",
    "import stable_baselines3\n",
    "print(stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2812c9-78a9-44a2-b997-431bc8498d51",
   "metadata": {},
   "source": [
    "### SB3 Example\n",
    "\n",
    "Note, it takes many iteraitons and the proper algorithm to get good results; this just shows it working.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066b6955-d608-4996-9f99-cba81995e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.3     |\n",
      "|    ep_rew_mean     | 21.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 2341     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.2         |\n",
      "|    ep_rew_mean          | 27.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2542         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008960325  |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | 0.0018279552 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.02         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.1        |\n",
      "|    ep_rew_mean          | 35.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1786        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009649758 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.091338575 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.6        |\n",
      "|    ep_rew_mean          | 48.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009611178 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.63       |\n",
      "|    explained_variance   | 0.22011024  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.2         |\n",
      "|    ep_rew_mean          | 64.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1488         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054460694 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.608       |\n",
      "|    explained_variance   | 0.2467668    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    value_loss           | 67.7         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "# Create the CartPole-v1 environment with the \"rgb_array\" render mode\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Create the PPO model (you can replace PPO with other algorithms if you want)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the agent for 10,000 steps\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Test the trained agent and render in the notebook\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Set up the plot for dynamic updates\n",
    "#plt.ion()  # Turn on interactive mode for matplotlib\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "\n",
    "    if done or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899a604-34d0-4299-be1c-96aaa804e34c",
   "metadata": {},
   "source": [
    "## Install Transformers and Tokenizers\n",
    "\n",
    "```\n",
    "pip install -U transformers tokenizers\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8825337-4ecb-483b-aff1-f649ee0d4f07",
   "metadata": {},
   "source": [
    "### Transformer and Tokenizer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b96fc0-bb19-4440-88f6-23db75f85940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31054a50f1549cbbcb9534c3edb92e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb12f03ecc49463d956a75fa8379a820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff220575b29c4823a11e15288f54748f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb63f73a588426ead6f0db252b49881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564c837dc1784e2484686d2d74399cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Transformers are amazing for NLP tasks.\n",
      "Tokenized Input IDs: tensor([[  101, 19081,  2024,  6429,  2005, 17953,  2361,  8518,  1012,   102]])\n",
      "Decoded Text: transformers are amazing for nlp tasks.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text\n",
    "text = \"Transformers are amazing for NLP tasks.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get the tokenized input IDs\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# Decode the token IDs back to text\n",
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print original text, tokenized input, and decoded text\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Tokenized Input IDs:\", input_ids)\n",
    "print(\"Decoded Text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af7930-6087-4db5-82f9-ae56de146383",
   "metadata": {},
   "source": [
    "## Sentence Transformers\n",
    "\n",
    "```/bash\n",
    "pip install sentence-transformers\n",
    "\n",
    "```\n",
    "\n",
    "Need this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254201e2-3fb5-4f0f-a346-dfed1abb0264",
   "metadata": {},
   "source": [
    "### Sentence Transformers Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f76f3b-253d-4df7-af11-cac9ee1bd986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4c5fcf1617463294ae193830aa0e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6ed1365d0840c799abd154a5a8d8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037d2bcf84e948eca47236ebd6b558c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6802320204ba41c3980300e1061606e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515067e1ebe14647ac34c864cca0d0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78f1158a7a04ed1a152948c036aa0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36235f6e6244926b2d4be9ba2d4809a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b0cbb06551482089d4d0340eb978dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb593b3ff63494fa3d88705d6553c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6641864c1f5f4e458b4a0be4685a6b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7babca68120451682d1509ed5a46542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.13390219e-02 -2.08391473e-02  3.78195010e-02 -1.00276247e-02\n",
      "  -2.18986869e-02  6.64145825e-03 -4.42283042e-02  4.97135967e-02\n",
      "   2.80647688e-02  1.45602077e-02  2.62471680e-02  8.02668929e-02\n",
      "   4.97582043e-03  8.78880396e-02  4.61269915e-02  3.79769169e-02\n",
      "   3.22095528e-02  1.52602587e-02 -4.78855744e-02 -8.71268660e-02\n",
      "   1.09329268e-01  8.22059661e-02  1.47923622e-02 -5.11703007e-02\n",
      "   5.15240654e-02  6.55859709e-02 -5.36913536e-02 -4.96964194e-02\n",
      "   3.65458615e-02 -9.47063603e-03 -4.13955376e-02  5.72569109e-02\n",
      "  -6.83491975e-02  5.84684871e-02 -6.26850054e-02  7.58527368e-02\n",
      "   1.44350678e-02  1.83785893e-02  1.41707724e-02 -5.39689176e-02\n",
      "  -3.47521007e-02 -1.90681871e-02  1.80511996e-02 -2.25276481e-02\n",
      "   4.55970392e-02 -3.47323604e-02 -2.73608956e-02 -1.98490638e-02\n",
      "  -8.14835308e-04 -2.79271062e-02 -3.95562649e-02 -5.84855452e-02\n",
      "   5.34983687e-02  1.18243933e-01 -1.34978304e-02  2.81568412e-02\n",
      "   8.00178573e-03 -5.52488901e-02  1.07748117e-02 -8.26784447e-02\n",
      "  -7.50691593e-02 -7.26945174e-04 -1.14284446e-02 -3.15912589e-02\n",
      "  -2.56440248e-02 -8.93278047e-03  2.13977061e-02 -1.95716554e-03\n",
      "  -3.98998931e-02  1.71870049e-02 -9.86917466e-02  4.32079732e-02\n",
      "   2.14145891e-02  7.41939768e-02  8.17541033e-02  1.30179888e-02\n",
      "   3.96499708e-02 -1.12352625e-01  1.61440484e-02 -4.75933030e-02\n",
      "   7.10801408e-02 -2.49396525e-02 -1.67710017e-02  1.02371007e-01\n",
      "   6.00531921e-02 -3.79600152e-02 -8.91840842e-04 -1.67397503e-02\n",
      "  -8.11639652e-02 -2.96590594e-03 -8.68671909e-02 -9.48272943e-02\n",
      "   8.75561014e-02  7.51268119e-03 -4.40817587e-02  2.50664521e-02\n",
      "  -4.81075980e-02 -7.26852342e-02  4.49802354e-03  3.30110043e-02\n",
      "  -9.52910632e-03 -2.88514420e-02  2.91740857e-02 -9.59848985e-02\n",
      "  -1.13295607e-01 -7.04405904e-02 -1.06132859e-02  1.11098439e-02\n",
      "  -3.91734950e-03 -4.05783467e-02  3.17186639e-02 -2.89384089e-02\n",
      "  -1.91743467e-02 -4.31948304e-02  6.17150702e-02 -8.93389359e-02\n",
      "   8.42679385e-03 -1.18960114e-02 -2.79277060e-02  3.27752382e-02\n",
      "   1.35773551e-02  7.54369423e-02 -4.16411906e-02  7.63626397e-02\n",
      "   2.60962211e-02 -3.30173708e-02  9.69682410e-02 -2.01159814e-33\n",
      "   8.41615070e-03  9.49250981e-02  4.12810780e-02  3.72696035e-02\n",
      "  -9.30488110e-03  3.43325525e-03 -2.14503650e-02  5.93382865e-02\n",
      "  -3.82257402e-02 -3.54575319e-03 -5.11288904e-02  8.00575465e-02\n",
      "  -1.72844864e-02 -1.36369036e-03 -1.50901396e-02 -6.47913516e-02\n",
      "  -3.30008753e-02  4.24928069e-02 -3.90296169e-02  3.09745632e-02\n",
      "  -6.61235489e-03  4.67417762e-02  3.62695940e-02 -2.47308798e-02\n",
      "  -3.20473462e-02 -3.44663742e-03 -1.98131008e-03 -6.16287068e-02\n",
      "   4.73357923e-02 -1.84988230e-02 -3.48375365e-02  5.97698204e-02\n",
      "  -5.21448739e-02  2.64986213e-02  5.34051331e-03  2.45025195e-03\n",
      "  -2.50871833e-02 -9.50678289e-02 -1.16135776e-02 -1.79991722e-02\n",
      "  -2.73287445e-02  5.74762858e-02 -1.10659592e-01  7.15818675e-03\n",
      "   7.70750344e-02  7.02132285e-02  2.04942096e-03 -4.28030267e-02\n",
      "   2.79471967e-02  1.98841118e-03  3.78896520e-02  5.34533374e-02\n",
      "  -5.07847778e-02  1.97710562e-03  1.83810994e-01 -7.26306438e-03\n",
      "   3.04949302e-02 -4.95866546e-03  1.00949436e-01  2.92118173e-02\n",
      "  -1.23772612e-02  3.00228801e-02  1.59176514e-02 -3.04648560e-02\n",
      "   4.33325544e-02 -2.02232897e-02  5.77010289e-02 -3.25591117e-03\n",
      "  -3.42636340e-04 -1.16551472e-02 -2.14825310e-02 -3.31576243e-02\n",
      "  -8.43165908e-04 -3.40886004e-02  1.86595377e-02  1.45057822e-02\n",
      "   2.44678091e-03 -4.46445048e-02  4.31090109e-02  5.86921722e-02\n",
      "  -4.85015325e-02 -1.19012073e-01  2.97993999e-02 -4.78464290e-02\n",
      "   2.59546824e-02 -4.82602566e-02 -3.18483859e-02 -9.71545801e-02\n",
      "   4.57095494e-03 -9.06092953e-03 -8.83268949e-04  2.50313878e-02\n",
      "  -2.26741899e-02  4.16877866e-03  5.73512726e-03  9.56815667e-34\n",
      "  -3.73278446e-02 -1.25536229e-02 -1.03082322e-01  9.87608358e-02\n",
      "  -2.94563118e-02 -1.43612493e-02 -3.82836424e-02  2.79907845e-02\n",
      "   2.47576796e-02  5.60509041e-02 -8.17171950e-03 -3.16256769e-02\n",
      "  -3.93590219e-02 -2.18429063e-02  1.09794021e-01 -6.70883879e-02\n",
      "   4.63268347e-02 -1.40530504e-02  4.11659405e-02  8.68671536e-02\n",
      "   1.58836078e-02  1.58808172e-01 -1.29776850e-01  4.66320962e-02\n",
      "  -9.48792882e-03  6.40924647e-02 -1.15770951e-01  7.14266906e-03\n",
      "   1.17837721e-02  9.03237704e-03 -4.31012735e-02 -1.03710266e-02\n",
      "  -1.86151657e-02 -2.15607435e-02 -5.08089289e-02 -1.17473239e-02\n",
      "  -2.72202864e-02 -1.23246918e-02 -2.62996033e-02  1.65909678e-02\n",
      "   3.03095039e-02  3.99106555e-02 -2.81111654e-02  2.47761589e-02\n",
      "  -9.52601582e-02 -6.82688355e-02 -3.33690904e-02 -4.25384268e-02\n",
      "  -2.54375022e-03  7.71383867e-02 -3.54083404e-02  1.09947724e-02\n",
      "  -1.12818182e-01 -1.21028438e-01 -1.52590862e-02 -5.44914268e-02\n",
      "   5.40055558e-02 -1.03101201e-01  2.88094059e-02 -1.97712164e-02\n",
      "  -9.30150822e-02  2.82325000e-02  8.50701332e-02 -5.99852614e-02\n",
      "   2.28142422e-02 -3.07086930e-02  1.59087982e-02 -2.78398767e-02\n",
      "  -2.87898607e-03 -2.72178501e-02  6.62283078e-02  3.70688178e-02\n",
      "   2.64303219e-02 -3.94684151e-02 -1.07483706e-02 -1.19048050e-02\n",
      "   4.18200791e-02  7.88501371e-03 -2.53780596e-02 -6.98991269e-02\n",
      "   3.05062030e-02  8.73478688e-03  5.21764979e-02  2.98741478e-02\n",
      "   1.51348710e-02  8.98343325e-02 -1.84008777e-02  1.12338900e-03\n",
      "   3.24808657e-02  6.21275902e-02 -3.42305191e-02  3.46834250e-02\n",
      "   2.67563239e-02  1.13286532e-01  1.31214708e-02 -1.58217173e-08\n",
      "  -5.14111370e-02  5.96944019e-02 -3.73664461e-02 -1.06354468e-02\n",
      "  -1.42139308e-02 -4.84036431e-02  3.31887901e-02  8.29870254e-02\n",
      "  -3.32706831e-02 -3.35255318e-04  9.80553851e-02 -4.55462635e-02\n",
      "   9.90803447e-03  4.91860732e-02  1.17603995e-01  1.87714286e-02\n",
      "   7.86552578e-02 -6.34163851e-03 -3.67030613e-02  8.07173550e-03\n",
      "  -8.98561906e-04  8.72058719e-02 -5.00192530e-02  8.99783522e-03\n",
      "  -2.44702976e-02  2.10707579e-02 -3.14436108e-02 -4.93638255e-02\n",
      "   2.44295374e-02 -1.39967045e-02  3.58098629e-03  4.92439047e-02\n",
      "  -2.20062844e-02  4.35395017e-02  5.47413453e-02  2.43604947e-02\n",
      "   7.40203559e-02 -7.40141049e-02 -1.90981552e-02 -3.42055708e-02\n",
      "   7.88776651e-02  7.65522420e-02 -9.69668701e-02  3.22016925e-02\n",
      "   4.90539595e-02 -2.78669875e-03  4.22286801e-02 -1.70268327e-01\n",
      "  -3.40080224e-02  3.91163910e-03  7.40140583e-03 -2.76136436e-02\n",
      "  -4.57474068e-02  2.54089925e-02  7.90525675e-02  3.73700485e-02\n",
      "   4.22542691e-02 -7.54245892e-02 -5.92881404e-02  7.13607147e-02\n",
      "   1.18065523e-02  7.82024711e-02  1.94492191e-02  4.77532558e-02]\n",
      " [-3.65059334e-03 -4.02565673e-02  5.37925698e-02  1.87592153e-02\n",
      "   4.36549187e-02  1.07265867e-01  1.37051512e-02  5.64765930e-02\n",
      "   3.83178368e-02 -3.81296463e-02  4.78521548e-02  4.42149341e-02\n",
      "   2.23990921e-02  6.06395677e-02  2.15431489e-02  3.58679853e-02\n",
      "   8.68860036e-02  9.80532914e-02 -7.73597211e-02 -8.74792784e-02\n",
      "  -4.10939790e-02  2.51762643e-02  6.71608299e-02 -6.30397052e-02\n",
      "   7.63506256e-03 -9.63681377e-03 -6.72210455e-02  3.96241480e-03\n",
      "   6.95275590e-02  2.14076992e-02 -2.73868535e-03 -4.66557266e-03\n",
      "  -2.08296292e-02  2.78403126e-02 -1.73364542e-02  2.82478556e-02\n",
      "   4.42461595e-02  1.06463179e-01 -4.13178578e-02 -2.04074904e-02\n",
      "   8.36506393e-03  2.78142802e-02  5.13444133e-02  6.12559132e-02\n",
      "   5.86420521e-02 -5.18060215e-02 -6.59484789e-02 -2.18247809e-02\n",
      "  -4.19921502e-02  4.15930301e-02 -6.09701835e-02 -2.82707699e-02\n",
      "  -3.88227589e-02  2.98456736e-02  2.10315436e-02 -6.47077942e-03\n",
      "  -3.32621522e-02 -1.17578944e-02  1.10785710e-02 -9.81175229e-02\n",
      "   1.67630147e-02 -5.59938438e-02 -3.41849141e-02  4.53318991e-02\n",
      "   3.42978463e-02 -6.97382586e-03  3.40201310e-03  5.35050482e-02\n",
      "  -5.67048863e-02  1.18010834e-01 -3.72043513e-02  2.63290592e-02\n",
      "  -8.92801359e-02  3.48123834e-02 -7.75281116e-02  4.94074970e-02\n",
      "   5.68245798e-02 -1.02483287e-01  6.50745556e-02 -2.24784017e-02\n",
      "  -3.21006104e-02 -2.35491879e-02  1.46478219e-02 -1.28406135e-03\n",
      "   1.17351875e-01 -1.12274401e-02  7.39701092e-02 -6.42866045e-02\n",
      "  -6.89552203e-02  2.77736615e-02  8.26351251e-03 -7.05972016e-02\n",
      "   4.64271717e-02 -6.82023866e-03  9.92723554e-03 -1.55898649e-02\n",
      "  -3.29162031e-02 -2.54919194e-02  1.22037558e-02  6.56328425e-02\n",
      "   3.29815559e-02  2.29997374e-02  7.80922249e-02  3.18656280e-03\n",
      "  -4.98883538e-02 -3.59912179e-02 -2.51075905e-02  1.59666110e-02\n",
      "   3.59950541e-03 -7.74265826e-02 -1.08642399e-01  4.89925742e-02\n",
      "  -2.34071817e-02  1.15038706e-02  5.48987463e-02 -2.53493059e-02\n",
      "   1.77409220e-02 -5.13559952e-02  4.09484021e-02 -1.90766901e-02\n",
      "  -2.71398462e-02  5.08160815e-02 -4.04529385e-02  4.74189706e-02\n",
      "   1.87084395e-02 -7.64883161e-02  1.77136473e-02 -3.10000709e-33\n",
      "  -1.21809132e-02  2.59609707e-02 -1.91357508e-02  6.19516484e-02\n",
      "   9.14470851e-03  1.42611498e-02 -4.55985405e-02  6.13452904e-02\n",
      "  -8.51536319e-02 -3.42709757e-02 -3.82091999e-02  5.97606599e-02\n",
      "   1.83344577e-02  1.04790628e-02  5.01671731e-02  1.86543427e-02\n",
      "  -2.31891144e-02  1.37787946e-02  1.65505381e-03  2.48640310e-02\n",
      "  -5.38350195e-02 -1.85126308e-02 -2.82224175e-03 -3.37436199e-02\n",
      "  -3.69313173e-02 -2.38055494e-02  1.20403104e-01 -6.21039420e-02\n",
      "  -4.12109084e-02  2.42502764e-02 -5.59023917e-02 -3.04967128e-02\n",
      "  -6.82481900e-02 -1.79481413e-02  2.20057182e-03  1.10733071e-02\n",
      "   1.02067355e-03 -3.48261297e-02  1.49891786e-02 -8.75054859e-03\n",
      "  -5.40854223e-03 -2.03850921e-02 -9.91617050e-03  2.04789010e-03\n",
      "   1.04808994e-02  1.72010215e-03 -9.23033431e-03 -3.43418866e-02\n",
      "   1.65516641e-02 -4.56563346e-02  1.09757418e-02  2.34715007e-02\n",
      "  -3.89116071e-03 -1.08842529e-01  1.05601966e-01 -2.06440017e-02\n",
      "  -1.60452109e-02  1.41883269e-02  2.73805130e-02 -4.69093397e-02\n",
      "  -1.50369061e-02  1.98541414e-02  9.58696455e-02 -3.54821384e-02\n",
      "  -3.42407972e-02  7.78523907e-02 -5.04240803e-02 -2.30546575e-02\n",
      "   1.91291478e-02  2.52683386e-02 -6.17241971e-02  3.61112282e-02\n",
      "  -2.04768721e-02 -6.49498357e-03 -4.58281562e-02  6.94495067e-02\n",
      "  -5.43259606e-02 -1.00172460e-01  3.08690518e-02  1.17122836e-01\n",
      "  -3.66332685e-03 -1.84244573e-01  1.39172086e-02 -1.40380422e-02\n",
      "  -3.96210067e-02 -1.41388029e-01  5.43647036e-02 -8.71689171e-02\n",
      "   6.75088316e-02  2.89072841e-02 -1.67964324e-02 -9.78566986e-03\n",
      "  -4.55208793e-02 -1.96134229e-03 -2.68604383e-02  1.68950001e-33\n",
      "  -3.31908651e-02  1.94349028e-02 -6.68849200e-02  6.47821203e-02\n",
      "  -8.55548959e-03  2.43360642e-02 -6.32420257e-02  1.61887649e-02\n",
      "  -2.44752895e-02 -1.50398351e-02 -8.92010108e-02  1.34052252e-02\n",
      "   4.28511612e-02 -4.46366183e-02  2.76253298e-02  5.50354086e-03\n",
      "  -4.14503701e-02  2.03786585e-02 -1.62264314e-02  4.22022268e-02\n",
      "   1.41476025e-03  9.94223431e-02 -5.71459681e-02  7.38420412e-02\n",
      "   4.14964892e-02  8.90615061e-02 -6.04642220e-02 -7.20138103e-02\n",
      "  -1.31157130e-01 -5.55766858e-02 -3.43461037e-02 -4.77558337e-02\n",
      "  -3.85389253e-02 -4.77391817e-02 -5.84639646e-02  3.23132463e-02\n",
      "   7.33683556e-02 -4.08573821e-02 -1.83145516e-02 -3.50779183e-02\n",
      "   5.94206527e-02  5.31809218e-02 -1.55666396e-02  2.80934684e-02\n",
      "  -1.04945870e-02 -1.43888695e-02 -7.55968094e-02 -1.17197996e-02\n",
      "   7.57965446e-02  5.81873953e-02 -4.25755754e-02  3.81851569e-02\n",
      "  -8.37945044e-02 -5.61070368e-02 -1.72014516e-02 -5.63367158e-02\n",
      "   2.60048267e-03 -1.02772810e-01 -1.26569124e-03 -1.56448204e-02\n",
      "  -1.09514169e-01 -3.83285619e-03  3.97503190e-02 -4.62057777e-02\n",
      "   5.93802445e-02 -1.39045298e-01 -3.16912308e-02  6.14068210e-02\n",
      "  -2.19796272e-03 -9.27407667e-02  1.07507445e-02 -3.91480653e-03\n",
      "  -3.00360508e-02  5.58332577e-02 -3.05788144e-02 -2.35126112e-02\n",
      "   3.72293219e-02  1.56597290e-02 -6.71997741e-02 -6.47743642e-02\n",
      "   8.87671858e-02 -7.48190582e-02  6.93876147e-02 -3.46382409e-02\n",
      "   3.34317833e-02  7.62093663e-02  3.34793031e-02 -2.96909455e-03\n",
      "   2.07741745e-02 -8.93895049e-03 -6.33102879e-02 -1.24691203e-02\n",
      "  -1.75032318e-02  1.17574818e-01  3.06492820e-02 -1.57105990e-08\n",
      "  -6.15324043e-02 -2.43087765e-02  5.48809208e-02  3.30633521e-02\n",
      "  -7.56444111e-02 -7.11501986e-02 -2.29836777e-02  6.43548518e-02\n",
      "  -5.09497747e-02 -3.36607918e-03  5.79673052e-02  2.19356436e-02\n",
      "  -6.35055453e-02  1.38764484e-02  4.74086516e-02  4.33153547e-02\n",
      "   5.74716413e-03 -1.79616343e-02 -3.80585575e-03  2.26669405e-02\n",
      "   5.74051216e-02  1.11191221e-01 -6.37346599e-03  4.52824123e-02\n",
      "  -1.78189054e-02  3.89134735e-02  1.69905126e-02  3.40933762e-02\n",
      "   2.54978295e-02  2.16917917e-02  5.06390892e-02  8.18909854e-02\n",
      "  -9.80566163e-03  4.50541172e-03  4.65276949e-02  1.29042089e-01\n",
      "   7.15280175e-02 -1.00724950e-01 -2.45595700e-04 -3.17358179e-03\n",
      "   5.04630469e-02  6.68728203e-02 -8.23084489e-02  3.21189612e-02\n",
      "   1.00300252e-01  4.13457630e-03  2.14018542e-02 -4.83180396e-02\n",
      "  -4.03572880e-02  3.44824512e-03  3.83811668e-02 -5.31096011e-02\n",
      "   5.30557614e-03  1.54014975e-02  3.79170403e-02  3.94546501e-02\n",
      "   3.25820819e-02 -2.72934549e-02 -5.38100256e-03  3.48101892e-02\n",
      "  -9.61131603e-03  1.74200386e-01  3.71564478e-02 -4.88811173e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode a list of sentences\n",
    "sentences = [\"Transformers are amazing for NLP tasks.\", \"Sentence embeddings are useful.\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the sentence embeddings\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4263a-5b09-4c82-9b14-77d8eefc3e3a",
   "metadata": {},
   "source": [
    "## Other Stuff\n",
    "\n",
    "If you are using Jupyter notebook, be sure to install `jupyterlab` and `ipywidgets` with pip.\n",
    "\n",
    "```.bash\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8975939-dfa8-4f6a-8835-08377eae50b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3727ee5a-377c-42ed-95f0-01cc268afd01",
   "metadata": {},
   "source": [
    "## Setup Summary -- \n",
    "\n",
    "More notes can be added here but Pytorch, and Stable Baselines 3 are the two main modules.  Extras required from both will come up but should not be a huge issue.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sb3)",
   "language": "python",
   "name": "sb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
