{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d8cb1d-899a-49d8-a041-cf216e8bb186",
   "metadata": {},
   "source": [
    "# Getting Started with SUBER\n",
    "\n",
    "SUBER is complex so we will take it one module at a time. The entry point for suber is [algorithms.mind.CFTrain2](https://github.com/acsheller/SUBER/blob/main/algorithms/mind/CF_train_A2C2.py).  One can review this file and simply get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531f245e-fadd-4903-affa-c71011f9a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd59a9ba31c4d6a83d2df59d6c56909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009469964b8747ee8e3972879e574475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97367d6a4548440ab07b005436248f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679fa7a56a20492db00de16217d6f4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784769163daf4c18b2e64a13376fb569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0221721f1e3d4729b8e2167d01c276ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b013261827f64c52b97174337eb1f48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4fc67d1713453888965a5d4bc0aabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5adf1874ee46eaa3415838fce0e24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eac696fd51942b6bfd07d591753bfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225396fa827f46da99621dbf867af568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e3337689a44d0180e0a0ab5e1ece5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5fba609c1248cd8d255dfbadcdb153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c313a5d608ce414cb0163f03ab5c51a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc0d8345d9c4dd6a5b67bf5fdc842f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust_model.ot:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from algorithms.wrappers import StableBaselineWrapperNum\n",
    "from environment.mind.configs import get_enviroment_from_args, get_base_parser\n",
    "from environment import load_LLM\n",
    "from algorithms.logging_config import get_logger\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "from stable_baselines3.common.distributions import CategoricalDistribution\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.preprocessing import get_flattened_obs_dim\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.type_aliases import TensorDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from typing import Callable, Tuple\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "import argparse\n",
    "import tqdm\n",
    "logger = get_logger(\"suber_logger\")\n",
    "\n",
    "# Set environment variable to avoid tokenizer parallelism issues\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624771a-cff1-4481-867b-e9d899049e99",
   "metadata": {},
   "source": [
    "## This is an example call to the system.  \n",
    "\n",
    "python3 -m algorithms.mind.CF_train_A2C2 --llm_model=TheBloke/Llama-2-13B-chat-GPTQ --llm_rater=2Shot_system_our --perturbator=gaussian --items_retrieval=most_similar_3_title --reward_shaping=exp_decay_time --embedding-dim=512 --gamma=0.95 --seed=42 --news_dataset=mind_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea7fded-c0cd-4804-8d9e-6eeae3c25bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = get_base_parser()\n",
    "    parser.add_argument(\"--model_device\", type=str, default=\"cuda:0\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.975)\n",
    "    parser.add_argument(\"--embedding_dim\", type=int, default=32)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.01)\n",
    "    parser\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--news_dataset', \n",
    "        choices=['mind_dataset', 'small_mind_dataset'], \n",
    "        help='Specify the news dataset to use',\n",
    "        default='small_mind_dataset'\n",
    "    )\n",
    "    # TODO Parser arguments should be here -- need to consider as most of them are \n",
    "    # in config.py\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffab37ae-8e18-49ac-8170-80bc45de4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear schedule function\n",
    "def linear_schedule(initial_value: float):\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        current_value = initial_value * progress_remaining\n",
    "        #print(f\"Linear schedule called: progress_remaining={progress_remaining}, learning_rate={current_value}\")\n",
    "        #logger.info(f\"Linear schedule called: progress_remaining={progress_remaining}, learning_rate={current_value}\")\n",
    "        return current_value\n",
    "    return func\n",
    "\n",
    "class CombinedCallback(BaseCallback):\n",
    "    def __init__(self, save_freq=50000, log_freq=5000, save_path=\"./tmp/models/\", name_prefix=\"rl_model\", verbose=0):\n",
    "        super(CombinedCallback, self).__init__(verbose)\n",
    "        self.save_freq = save_freq\n",
    "        self.log_freq = log_freq\n",
    "        self.save_path = save_path\n",
    "        self.name_prefix = name_prefix\n",
    "        self.metrics = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.log_freq == 0:\n",
    "            rewards = self.locals['rewards']\n",
    "            episode_length = self.locals.get('episode_lengths', None)\n",
    "            value_loss = self.locals.get('value_loss', None)\n",
    "            policy_loss = self.locals.get('policy_loss', None)\n",
    "            if value_loss is not None:\n",
    "                log_message = {\n",
    "                    \"step\": self.num_timesteps,\n",
    "                    \"reward\": rewards,\n",
    "                    \"episode_length\": episode_length,\n",
    "                    \"value_loss\": value_loss,\n",
    "                    \"policy_loss\": policy_loss\n",
    "                }\n",
    "                self.metrics.append(log_message)\n",
    "                self.logger.info(log_message)\n",
    "\n",
    "\n",
    "        if self.n_calls % self.save_freq == 0:\n",
    "            model_path = f\"{self.save_path}/{self.name_prefix}_{self.num_timesteps}_steps\"\n",
    "            self.model.save(model_path)\n",
    "            if self.verbose > 0:\n",
    "                print(f\"Saving model checkpoint to {model_path}\")\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f698f-ca7c-4e4c-85a2-c69f8296061f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcad418-a757-4ccd-8ca6-1b61d7afdaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_space: gym.spaces.Space, num_users: int, num_items: int, learning_rate: float = 0.001):\n",
    "        super().__init__()\n",
    "        embedding_dim = args.embedding_dim\n",
    "        self.latent_dim_pi = embedding_dim * 2\n",
    "        self.latent_dim_vf = embedding_dim * 2\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "\n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Linear(self.user_embedding.embedding_dim, embedding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim * 2, embedding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim * 4, num_items)\n",
    "        )\n",
    "\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(self.user_embedding.embedding_dim + num_items, self.latent_dim_vf * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.latent_dim_vf * 2, embedding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim * 4, self.latent_dim_vf),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: TensorDict) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        user_id = features[\"user_id\"].squeeze(1)\n",
    "        news_seen = features[\"items_interact\"]\n",
    "\n",
    "        user_embedding = self.user_embedding(user_id)\n",
    "        user_embedding_value = torch.cat([user_embedding, news_seen], dim=1)\n",
    "        user_bias = self.user_bias(user_id)\n",
    "\n",
    "        mask = features[\"items_interact\"].to(dtype=torch.bool)\n",
    "        logits = self.policy_net(user_embedding) + user_bias\n",
    "        logits[mask] = -torch.inf\n",
    "        return logits, self.value_net(user_embedding_value)\n",
    "\n",
    "    def forward_actor(self, features: TensorDict) -> torch.Tensor:\n",
    "        user_id = features[\"user_id\"].squeeze(1)\n",
    "        user_embedding = self.user_embedding(user_id)\n",
    "        user_bias = self.user_bias(user_id)\n",
    "\n",
    "        mask = features[\"items_interact\"].to(dtype=torch.bool)\n",
    "        logits = self.policy_net(user_embedding) + user_bias\n",
    "        logits[mask] = -torch.inf\n",
    "        return logits\n",
    "\n",
    "    def forward_critic(self, features: TensorDict) -> torch.Tensor:\n",
    "        user_id = features[\"user_id\"].squeeze(1)\n",
    "        news_seen = features[\"items_interact\"]\n",
    "\n",
    "        user_embedding = self.user_embedding(user_id)\n",
    "        user_embedding_value = torch.cat([user_embedding, news_seen], dim=1)\n",
    "        return self.value_net(user_embedding_value)\n",
    "\n",
    "class DistributionUseLogitsDirectly(CategoricalDistribution):\n",
    "    def __init__(self, action_dim: int):\n",
    "        super().__init__(action_dim)\n",
    "\n",
    "    def proba_distribution_net(self, latent_dim: int) -> nn.Module:\n",
    "        return nn.Identity(latent_dim)\n",
    "\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, observation_space: spaces.Space, action_space: spaces.Space, lr_schedule: Callable[[float], float], *args, **kwargs):\n",
    "        kwargs[\"ortho_init\"] = True\n",
    "        super().__init__(observation_space, action_space, lr_schedule, *args, **kwargs)\n",
    "\n",
    "        self.action_dist = DistributionUseLogitsDirectly(action_space.n)\n",
    "        self._build(lr_schedule)\n",
    "\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        default_lr = 0.01\n",
    "        num_users = train_env.get_wrapper_attr('num_users')\n",
    "        num_items = train_env.get_wrapper_attr('num_items')\n",
    "        self.mlp_extractor = Net(self.observation_space, num_users, num_items, learning_rate=default_lr)\n",
    "\n",
    "class ExtractPass(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space) -> None:\n",
    "        super().__init__(observation_space, get_flattened_obs_dim(observation_space))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        observations[\"user_id\"] = observations[\"user_id\"].int()\n",
    "        return observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37f9008-d456-43ae-a0ac-ab27b6fcad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = parse_args()\n",
    "#args.llm_model='llama3.2'\n",
    "#llm = load_LLM(args.llm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f1bb6-528b-4187-853d-0329a73b0e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320e1e3-58d5-46c3-8a13-e34a67dd9a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e6718-d51b-4cfd-9662-2388fc2e2c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "601d07d1-cebf-4acc-aa71-8fe7eae9b5b3",
   "metadata": {},
   "source": [
    "# Example Usage of Ollama\n",
    "from environment.LLM.ollama import OllamaLLM\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ollama = OllamaLLM(\"llama3.2\")\n",
    "    prompt = \"Hello, how can you assist me today?\"\n",
    "    dialog = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    system_prompt = (\n",
    "        \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, \"\n",
    "        \"while being safe and unbiased. Please do not include any harmful or unethical content.\"\n",
    "    )\n",
    "    encoded_prompt = f\"{system_prompt}\\n\\n\" + \"\\n\".join(f\"{d['role']}: {d['content']}\" for d in dialog)\n",
    "\n",
    "    response = ollama._query_ollama(encoded_prompt)\n",
    "    #print(\"Prompt Sent:\", prompt)\n",
    "    print(\"Response Received:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8e41a-5f3c-4b61-a38b-839ae8e12862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ada295f-4c90-4f42-a1c9-b7e0be03cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name is TheBloke/Llama-2-7b-Chat-GPTQ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc90ed3a111d43ff97d813aae409997d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc333f9be324cc6bce39be6bcba8d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Notice:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed965734d194eb0aba97c9ceaa4ec1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d91da853a84f71aa09ec09aac5d550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/25.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0b3278acc24b7db33090ae831b2b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abae34723ce45ecaf52235a019f1c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5b5c808bf41bb865ef4b42a181fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8754ffdffa4f2fb32eebc3b8efb457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "USE_POLICY.md:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afe0937444d4f1fb326e60fd22911cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "quantize_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e566a62732b43dba54833ace268c946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09a61f6dfaa4debbc12f0d3d0431447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0f00b3f3d847a28224a50048bbd3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebc28c1b8724657afbdf9cfa7c17a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19a7520bcbe4050a24515920f05c127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training environment\n",
      "Checking Test Environment\n",
      "Creating A2C Model\n",
      "Using cuda:0 device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Callback being created\n",
      "Model begining to learn\n",
      "Logging to /app/SUBERX/models/TheBloke_Llama-2-7b-Chat-GPTQ___2Shot_system_our___last_3___mind___small_mind_dataset___none___exp_decay_time___42___cuda_0___0_975___32___0_01/t_logs_20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebd009a728048869e414bbadaee0fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 48.6     |\n",
      "|    ep_rew_mean        | 377      |\n",
      "| time/                 |          |\n",
      "|    fps                | 3        |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.3    |\n",
      "|    explained_variance | -0.00991 |\n",
      "|    learning_rate      | 0.0095   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 224      |\n",
      "|    value_loss         | 572      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel starts learning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel begining to learn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt_logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Ends Learning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Ends Learning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/stable_baselines3/a2c/a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/gymnasium/core.py:550\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    548\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001b[0;32m/app/SUBERX/environment/env.py:219\u001b[0m, in \u001b[0;36mSimulatio4RecSysMind.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mfork_rng([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    218\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_seed)\n\u001b[0;32m--> 219\u001b[0m     rating, explanation, html_interaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrating_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueryMind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurr_item\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_interacted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretrieved_interactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretrieved_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_seed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03mAfter collecting the explanation and the rating from the LLM the next step is to select the item \u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m(but this only in the case more than one is recommended)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/app/SUBERX/environment/LLM/rater.py:205\u001b[0m, in \u001b[0;36mLLMRater.queryMind\u001b[0;34m(self, user, item, num_interacted, interactions, retrieved_items)\u001b[0m\n\u001b[1;32m    200\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prompt(\n\u001b[1;32m    201\u001b[0m     user, item, num_interacted, interactions, retrieved_items\n\u001b[1;32m    202\u001b[0m )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_scale \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0-9\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 205\u001b[0m     _, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_rating_0_9\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfew_shot_prompts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         rating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madjust_rating_out(\u001b[38;5;28mfloat\u001b[39m(out))\n",
      "File \u001b[0;32m/app/SUBERX/environment/LLM/exllama.py:128\u001b[0m, in \u001b[0;36mLLMExllama.request_rating_0_9\u001b[0;34m(self, system_prompt, dialog)\u001b[0m\n\u001b[1;32m    126\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(system_prompt, dialog)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cache:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompt, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reuse_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator_rating_0_9\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator_rating_0_9\u001b[38;5;241m.\u001b[39mgenerate_simple(\n\u001b[1;32m    133\u001b[0m         prompt, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m     )\n",
      "File \u001b[0;32m/app/SUBERX/environment/LLM/exllama.py:194\u001b[0m, in \u001b[0;36mLLMExllama.generate_reuse_simple\u001b[0;34m(self, generator, prompt, max_new_tokens)\u001b[0m\n\u001b[1;32m    192\u001b[0m eos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[0;32m--> 194\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_single_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(token\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token[j, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m generator\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id:\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/exllama/generator.py:352\u001b[0m, in \u001b[0;36mExLlamaGenerator.gen_single_token\u001b[0;34m(self, constraints, mask)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Simple sampling case:\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_rep_penalty(logits)\n\u001b[1;32m    355\u001b[0m     logits[:, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbos_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10000.0\u001b[39m\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/exllama/model.py:960\u001b[0m, in \u001b[0;36mExLlama.forward\u001b[0;34m(self, input_ids, cache, last_id_only, preprocess_only, lora, output_device, input_mask)\u001b[0m\n\u001b[1;32m    957\u001b[0m _last_id_only \u001b[38;5;241m=\u001b[39m last_id_only\n\u001b[1;32m    958\u001b[0m _preprocess_only \u001b[38;5;241m=\u001b[39m preprocess_only \u001b[38;5;129;01mor\u001b[39;00m (chunk_end \u001b[38;5;241m<\u001b[39m q_len \u001b[38;5;129;01mand\u001b[39;00m last_id_only)\n\u001b[0;32m--> 960\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_begin\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m_last_id_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m_preprocess_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlora\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m                 \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _preprocess_only:\n\u001b[1;32m    969\u001b[0m     result \u001b[38;5;241m=\u001b[39m r \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((result, r), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/exllama/model.py:1069\u001b[0m, in \u001b[0;36mExLlama._forward\u001b[0;34m(self, input_ids, cache, last_id_only, preprocess_only, lora, output_device, input_mask)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# logits = cuda_ext.matmul_half(hidden_states, self.lm_head_data, cublas = False)\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m-> 1069\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43m_move_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/app/sb3/lib/python3.10/site-packages/exllama/model.py:701\u001b[0m, in \u001b[0;36m_move_tensor\u001b[0;34m(tensor, new_device, name, config)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(new_device)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    700\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    #args.llm_model='llama3.2'\n",
    "    llm = load_LLM(args.llm_model)\n",
    "\n",
    "    dir_name = f\"{args.llm_model}___{args.llm_rater}___{args.items_retrieval}___{args.user_dataset}___{args.news_dataset}___{args.perturbator}___{args.reward_shaping}___{args.seed}___{args.model_device}___{args.gamma}___{args.embedding_dim}___{args.learning_rate}\"\n",
    "    sanitized_dir_name = dir_name.replace('/', '_').replace(':', '_').replace('.', '_')\n",
    "    save_path = f\"/app/SUBERX/models/{sanitized_dir_name}\"\n",
    "    wandb_path = f\"/app/wandb\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    train_env = get_enviroment_from_args(llm, args)\n",
    "    test_env = get_enviroment_from_args(llm, args, seed=args.seed + 600)\n",
    "\n",
    "    policy_kwargs = dict(features_extractor_class=ExtractPass)\n",
    "    train_env = StableBaselineWrapperNum(train_env)\n",
    "    test_env = Monitor(StableBaselineWrapperNum(test_env))\n",
    "    print(\"Checking training environment\")\n",
    "    check_env(train_env, warn=True)\n",
    "\n",
    "    print(\"Checking Test Environment\")\n",
    "    check_env(test_env)\n",
    "\n",
    "    print(\"Creating A2C Model\")\n",
    "    model = A2C(\n",
    "        CustomActorCriticPolicy,\n",
    "        train_env,\n",
    "        verbose=1,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        device=args.model_device,\n",
    "        learning_rate=linear_schedule(args.learning_rate),\n",
    "        tensorboard_log=save_path,\n",
    "        gamma=args.gamma,\n",
    "        ent_coef=0.001,\n",
    "    )\n",
    "    print(\"Callback being created\")\n",
    "    combined_callback = CombinedCallback(save_freq=2500, log_freq=500, save_path=save_path, name_prefix=\"rl_model\", verbose=1)\n",
    "    callback = CallbackList([combined_callback])\n",
    "\n",
    "    logger.info(\"Model starts learning\")\n",
    "    print(\"Model begining to learn\")\n",
    "    model.learn(total_timesteps=10000, progress_bar=True, callback=callback, tb_log_name=\"t_logs\")\n",
    "\n",
    "    logger.info(\"Model Ends Learning\")\n",
    "    print(\"Model Ends Learning\")\n",
    "    logger.info(\"Evaluating the Policy\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, test_env, n_eval_episodes=50)\n",
    "    logger.info(f\"Mean reward: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "    reward_file_path = os.path.join(save_path, f\"reward_{mean_reward:.2f}.txt\")\n",
    "    with open(reward_file_path, 'w') as file:\n",
    "        file.write(f\"Mean reward: {mean_reward} +/- {std_reward}\\n\")\n",
    "\n",
    "    print(f\"Reward information saved to {reward_file_path}\")\n",
    "\n",
    "    print(f\"Mean Reward: {mean_reward} +/- {std_reward}\")\n",
    "    logger.info(f\"Mean Reward: {mean_reward} +/- {std_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e229ec-51b5-451f-a6b7-767ba1124a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e656d-ad86-45d6-99ab-ef86d237ef20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
