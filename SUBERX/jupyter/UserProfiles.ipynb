{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21343446-84be-4944-b10f-d8dddb11f7e0",
   "metadata": {},
   "source": [
    "## Crafting User Profiles from the original data\n",
    "\n",
    "The concept will be to extract the original datasets and shape them into analysts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ba3d2c-1c36-4a75-b3c7-1f6abf5b27d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behaviors File /app/datasets/MINDsmall/train/behaviors.tsv\n",
      "News file /app/datasets/MINDsmall/train/news.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time\n",
    "\n",
    "MIND_type = 'MINDsmall'\n",
    "\n",
    "data_path_base=\"/app/datasets/\"\n",
    "data_path = data_path_base + MIND_type +\"/\"\n",
    "\n",
    "\n",
    "behaviors_file = data_path + \"train/behaviors.tsv\"\n",
    "print(f\"Behaviors File {behaviors_file}\")\n",
    "\n",
    "news_file = data_path + \"train/news.tsv\"\n",
    "news_df = pd.read_csv(news_file, sep=\"\\t\", names=[\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"])\n",
    "print(f\"News file {news_file}\")\n",
    "# Load the behaviors data\n",
    "columns = [\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "behaviors_df = pd.read_csv(behaviors_file, sep=\"\\t\", names=columns)\n",
    "\n",
    "# Display basic statistics and data sample\n",
    "#print(behaviors_df.info())\n",
    "\n",
    "\n",
    "def print_elapsed_time(start_time):\n",
    "    \"\"\"\n",
    "    Print the elapsed time since `start_time` in hours, minutes, and seconds.\n",
    "    \n",
    "    Args:\n",
    "        start_time (float): The starting time, typically obtained from time.time().\n",
    "    \"\"\"\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Elapsed Time: {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68891a5-13f1-4d4c-a1a0-fef6ccb16144",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f3c9b-a4da-4a56-93cf-5c426d2e43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8965bd6-35cc-4379-90c3-80db294bc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in 'history_articles' with empty lists\n",
    "behaviors_df['history_articles'] = behaviors_df['history_articles'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Count session length (history length)\n",
    "behaviors_df['session_length'] = behaviors_df['history_articles'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0896c5-c3e0-4c6a-a81e-34034180a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse impressions and clicks\n",
    "def parse_impressions(impressions_str):\n",
    "    impressions = impressions_str.split(\" \")\n",
    "    return [(imp.split(\"-\")[0], int(imp.split(\"-\")[1])) for imp in impressions]\n",
    "\n",
    "behaviors_df['impressions_parsed'] = behaviors_df['impressions'].apply(parse_impressions)\n",
    "\n",
    "# Calculate CTR per session\n",
    "behaviors_df['ctr'] = behaviors_df['impressions_parsed'].apply(lambda imp: sum([click for _, click in imp]) / len(imp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c4e35-bb1c-4be0-80c7-adec8c98fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e33c6-2375-49f7-97b4-90902f83cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user to aggregate data\n",
    "user_profiles = behaviors_df.groupby('user_id').agg({\n",
    "    'session_length': 'mean',\n",
    "    'ctr': 'mean',\n",
    "    'history_articles': 'sum'  # Combine history across sessions\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f72a2-1d8f-4fbb-a519-c4daa56afee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map history articles to topics using news.tsv\n",
    "news_topic_mapping = news_df.set_index('news_id')['category'].to_dict()\n",
    "user_profiles['topics'] = user_profiles['history_articles'].swifter.apply(\n",
    "    lambda articles: pd.Series(articles).map(news_topic_mapping).value_counts(normalize=True).to_dict()\n",
    ")\n",
    "\n",
    "print(user_profiles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256cbe2-45b7-4309-b532-b791463e8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5cd2f-e7d6-471c-9ea3-442a51a04588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6c32b-f8a4-4e38-adfe-43e907a93e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sb3)",
   "language": "python",
   "name": "sb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
