{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37301e2e-a92f-4155-aaa4-a46cb0fd58ef",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008fe6e-8d55-431f-9056-8fd66c374552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "import random\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from typing import Dict, Optional, List\n",
    "\n",
    "# Imports for Pydantic AI\n",
    "from pydantic_ai import Agent\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from pydantic_ai.models.ollama import OllamaModel\n",
    "\n",
    "from environment.LLM.analyst_behavior import AnalystBehavior, AnalystBehaviorSimulator, main\n",
    "# Depending on if you are working in the container or not.  \n",
    "# data_path_base = \"/home/asheller/cicero/datasets/\" Would be outside the container\n",
    "#data_path_base = \"/app/datasets/\"\n",
    "\n",
    "# It is currently set to\n",
    "data_path_base = \"/app/datasets/\"\n",
    "\n",
    "model_name = \"mistral:7b\"  # Replace with your preferred model\n",
    "#model_name = \"llama3.2\"  # Replace with your preferred model\n",
    "#model_name = \"deepseek-r1:7b\"  # Replace with your preferred model\n",
    "model_name = \"cogito:8b\"   # Replace with your preferred model\n",
    "\n",
    "base_url = \"http://olloma:11434/v1/\"  # Ollama's default base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08d923-acb7-4a03-b480-6b7886095d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # With no arguments it will run for 3x the number of analysts.\n",
    "    # Depending on if you are working in the container or not.  \n",
    "    #data_path_base = \"/home/asheller/cicero/datasets/\" #Would be outside the container\n",
    "    data_path_base = \"/app/datasets/\" # Inside the contaainer\n",
    "\n",
    "\n",
    "    #model_name = \"mistral:7b\"  # Replace with your preferred model\n",
    "    #model_name = \"llama3.2\"  # Replace with your preferred model\n",
    "    model_name = \"cogito:8b\"  # Replace with your preferred model\n",
    "    base_url = \"http://ollama:11434/v1/\"  # Ollama's default base URL inside container\n",
    "    #base_url = \"http://localhost:11434/v1/\"  # Ollama's default base URL outside container \n",
    "\n",
    "\n",
    "    # In the notebook use await, at a python prompt use asyncio\n",
    "    # Review the main method of the \n",
    "    await main(data_path_base=data_path_base, MIND_type=\"MINDsmall\", model_name=model_name,base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7676d0-f05f-4e3a-917b-db70cfbf483c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sb3)",
   "language": "python",
   "name": "sb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
