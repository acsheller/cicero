{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57f4dc5-e2d4-48af-b634-a36f1b0ba6bc",
   "metadata": {},
   "source": [
    "# CICERO -- NRMS Small Dataset Adapted\n",
    "\n",
    "This notebook is a run of the [NRMS notebook]( adapted from the [Recommenders Team](https://github.com/recommenders-team/recommenders/tree/main).  It has been modified as time has caused some things to not work as presneted originally.\n",
    "\n",
    "NRMS stands for `Neural News Reccomendaiton with Multi-head Self-Attention`.  The reference to the paper is provided below. please look over and study the [recommenders team github repository](https://github.com/recommenders-team/recommenders/blob/main/README.md#Getting-Started) because this code is derived from it. \n",
    "\n",
    "Read up on the [MIND: MIcrosoft News Dataset](https://msnews.github.io/) and download the data into the datasets folder of this project and place them in `/apps/datasets`.  Review the [Readme](/app/datasets/README.md) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc102976-1a42-45a9-b451-a81e5341ead2",
   "metadata": {},
   "source": [
    "## do imports and check things out.\n",
    "\n",
    "Are we using a GPU? If not then things will take a very long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff884381-7536-4fcf-ad55-c1ba57a1204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3eb0e2e46b4d6ba2ce2c9fdd1c8302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b15030572fe4403bd628e0746277cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e0072baaae4d4fa6a18f24429cbde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05c5890e23c47ec98cc059b9f09a4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd12bb332e4c43f0897799e6b4d44302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d16cd105b84a718aebbc89929912a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c6fe08ece040f192fd876f36a98fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9492bf4aa1475282ba8657e2264f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccda36a6d819474fb3d4e3858f46ac42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a323992a52346dfa69968aca903556d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411394884b8d49c5a1a5ff7f5f30de63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c982a627a9c44808b2758dc05573a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44048a4278d440881e964e591131527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c88ddd1b34744a8ac554aedcd444625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a7ea50fb4a49e09fb2985b48109255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust_model.ot:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
      "Tensorflow version: 2.15.1\n",
      "Available devices:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPU is available and TensorFlow is using it.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Remove warnings\n",
    "import os\n",
    "os.environ['TF_TRT_ALLOW_ENGINE_NATIVE_SEGMENT_EXECUTION'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import sys\n",
    "# Gets the SUBERX python modules included.\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from tempfile import TemporaryDirectory\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "# This module was created to generate the necessary files if they dont' already exist\n",
    "from environment.data_utils import generate_uid2index, load_glove_embeddings, create_word_dict_and_embeddings, setup_nltk_resources\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.datasets.mind import download_and_extract_glove\n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "from recommenders.models.newsrec.models.nrms import NRMSModel\n",
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "from recommenders.utils.notebook_utils import store_metadata\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "\n",
    "# List available devices\n",
    "print(\"Available devices:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(device)\n",
    "\n",
    "# Check if a GPU is detected\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available and TensorFlow is using it.\")\n",
    "else:\n",
    "    print(\"GPU is NOT available. TensorFlow is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af570-5c83-4b45-bd09-41ccf60f9bea",
   "metadata": {},
   "source": [
    "## Prepare Parameters\n",
    "\n",
    "Adjust these as needed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5974d7-912e-4bff-b82e-6eb54aef5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "seed = 42\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# My modification for MINDSMALL as I mount in the data into the container.  Further the small dataset is not accessable anymore.\n",
    "\n",
    "# Options: MINDdemo, MINDsmall, MINDlarge\n",
    "\n",
    "MIND_type = 'MINDsmall'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d489c-d20a-466a-9272-1384108a3032",
   "metadata": {},
   "source": [
    "## Specify the dataset to use\n",
    "\n",
    "There are three in the original notebook: `demo`, `small` and `large`.\n",
    "\n",
    "From the [original  notebook](https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb),  the `demo` set is 5000 samples of the `small` dataset.\n",
    "\n",
    "I was able to download the original demo but that's not really needed. A sample of 5000 is good for showing the algorithm works but won't train it well enough.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29954d8-37fb-422d-9b3f-fc874fe01510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path is /app/datasets/MINDsmall\n"
     ]
    }
   ],
   "source": [
    "## This is how it was done originally\n",
    "#tmpdir = TemporaryDirectory()\n",
    "#data_path = tmpdir.name\n",
    "\n",
    "## I mount in the datasets folder to /app\n",
    "data_path_base=\"/app/datasets/\"\n",
    "data_path = data_path_base + MIND_type\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "print(f\"Data Path is {data_path}\")\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "dev_news_file = os.path.join(data_path,'dev','news.tsv')\n",
    "dev_behaviors_file = os.path.join(data_path,'dev','behaviors.tsv')\n",
    "\n",
    "wordEmb_file = os.path.join(data_path, 'utils',\"embedding.npy\")\n",
    "userDict_file = os.path.join(data_path, 'utils',\"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, 'utils',\"word_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\",'nrms.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610d53a-c6a9-44e0-a82f-3b38838c3b0f",
   "metadata": {},
   "source": [
    "## Download Glove embeddings\n",
    "\n",
    "The original NRMS used glove embeddings, this is how they are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e9bf3e-275d-4371-9776-639ce23b1400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings extracted to: /app/datasets/glove_embeddings\n"
     ]
    }
   ],
   "source": [
    "## All models can use the same glove embeddings\n",
    "\n",
    "# Download and extract GloVe embeddings\n",
    "glove_dir = data_path_base +'glove_embeddings'\n",
    "download_and_extract_glove(glove_dir)\n",
    "print(f\"GloVe embeddings extracted to: {glove_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e611ac-a694-4521-add9-81ec629fc667",
   "metadata": {},
   "source": [
    "## Get the NLTK Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418f7f76-92e7-4eba-8e8a-b0cb1155c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /app/datasets/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources downloaded to /app/datasets/nltk_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /app/datasets/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk_data_dir = data_path_base + 'nltk_data'\n",
    "setup_nltk_resources(download_dir=nltk_data_dir)\n",
    "nltk.data.path.append(nltk_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59afa67-e97c-4fff-be7f-723471666196",
   "metadata": {},
   "source": [
    "## Identify the news and behavior files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdbd3c9b-53e4-431f-9762-5fed967ba323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/datasets/MINDsmall/utils/uid2index.pkl already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Generate uid2index.pkl\n",
    "uid2index = generate_uid2index(train_behaviors_file, output_file= userDict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a554c70d-07cd-4f5e-87b9-685dbc1aabbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_embeddings.pkl already exists. Loading embeddings from file.\n"
     ]
    }
   ],
   "source": [
    "# Path to GloVe file (e.g., glove.6B.300d.txt)\n",
    "glove_file = os.path.join(glove_dir, \"glove/glove.6B.300d.txt\")\n",
    "embedding_dim = 300\n",
    "glove_embeddings = load_glove_embeddings(glove_file, embedding_dim=embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "127a1c71-3e93-4b53-b00f-d63c1330b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already exist in /app/datasets/MINDsmall/utils/. Loading existing word_dict and embedding matrix.\n"
     ]
    }
   ],
   "source": [
    "# Generate word_dict.pkl and embedding.npy\n",
    "word_dict, embedding_matrix = create_word_dict_and_embeddings(\n",
    "    news_file= train_news_file,\n",
    "    glove_embeddings=glove_embeddings,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dir= data_path + '/utils/'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95affeba-a5ff-4c52-9dc3-0c5ad23153c3",
   "metadata": {},
   "source": [
    "## Define the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77dba2ff-4428-47a5-9cb7-298d8def9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = prepare_hparams(None, \n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          wordDict_file=wordDict_file, \n",
    "                          userDict_file=userDict_file,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          model_type=\"nrms\",\n",
    "                          title_size=30,\n",
    "                          his_size=50,\n",
    "                          npratio=4,\n",
    "                          data_format='news',\n",
    "                          word_emb_dim=300,\n",
    "                          head_num=20,\n",
    "                          head_dim=20,\n",
    "                          attention_hidden_dim=200,\n",
    "                          loss='cross_entropy_loss',\n",
    "                          dropout=0.2,\n",
    "                          support_quick_scoring=True,\n",
    "                          show_step=10, \n",
    "                          metrics=['group_auc', 'mean_mrr', 'ndcg@5;10'])\n",
    "#print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d083bd0-20ca-4356-b9e4-15c9d08d1da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support_quick_scoring = True\n",
      "dropout = 0.2\n",
      "attention_hidden_dim = 200\n",
      "head_num = 20\n",
      "head_dim = 20\n",
      "filter_num = 200\n",
      "window_size = 3\n",
      "vert_emb_dim = 100\n",
      "subvert_emb_dim = 100\n",
      "gru_unit = 400\n",
      "type = ini\n",
      "user_emb_dim = 50\n",
      "learning_rate = 0.001\n",
      "optimizer = adam\n",
      "epochs = 5\n",
      "batch_size = 64\n",
      "show_step = 10\n",
      "wordEmb_file = /app/datasets/MINDsmall/utils/embedding.npy\n",
      "wordDict_file = /app/datasets/MINDsmall/utils/word_dict.pkl\n",
      "userDict_file = /app/datasets/MINDsmall/utils/uid2index.pkl\n",
      "model_type = nrms\n",
      "title_size = 30\n",
      "his_size = 50\n",
      "npratio = 4\n",
      "data_format = news\n",
      "word_emb_dim = 300\n",
      "loss = cross_entropy_loss\n",
      "metrics = ['group_auc', 'mean_mrr', 'ndcg@5;10']\n"
     ]
    }
   ],
   "source": [
    "for i in hparams.values().keys():\n",
    "    print(f\"{i} = {hparams.values()[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4093f31e-49ad-4ceb-87f0-586681c0f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "iterator = MINDIterator\n",
    "model = NRMSModel(hparams, iterator, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a149ab9f-3527-430f-993f-ae93c557956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model without any training -- can training do better than no training at all?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18901dab-1155-4a46-a654-baf24cd6495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/sb3/lib/python3.10/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "663it [00:03, 177.06it/s]\n",
      "1143it [00:51, 22.38it/s]\n",
      "73152it [00:12, 5637.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.4621, 'mean_mrr': 0.1991, 'ndcg@5': 0.2, 'ndcg@10': 0.2625}\n"
     ]
    }
   ],
   "source": [
    "print(model.run_eval(dev_news_file, dev_behaviors_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da9eec7-a401-4302-84c9-3bed9b9c7654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 3690 , total_loss: 1.3564, data_loss: 1.2460: : 3693it [11:41,  5.27it/s]\n",
      "663it [00:01, 438.94it/s]\n",
      "1143it [00:46, 24.36it/s]\n",
      "73152it [00:12, 5964.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 1\n",
      "train info: logloss loss:1.3563891566932733\n",
      "eval info: group_auc:0.6434, mean_mrr:0.2919, ndcg@10:0.3877, ndcg@5:0.3193\n",
      "at epoch 1 , train time: 701.4 eval time: 152.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 3690 , total_loss: 1.2646, data_loss: 1.2478: : 3693it [11:30,  5.35it/s]\n",
      "663it [00:01, 387.77it/s]\n",
      "1143it [00:48, 23.66it/s]\n",
      "73152it [00:11, 6146.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 2\n",
      "train info: logloss loss:1.2646360734985542\n",
      "eval info: group_auc:0.6437, mean_mrr:0.2961, ndcg@10:0.3908, ndcg@5:0.3238\n",
      "at epoch 2 , train time: 690.1 eval time: 154.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 3690 , total_loss: 1.2219, data_loss: 1.1531: : 3693it [11:31,  5.34it/s]\n",
      "663it [00:01, 417.00it/s]\n",
      "1143it [00:48, 23.81it/s]\n",
      "73152it [00:12, 5674.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 3\n",
      "train info: logloss loss:1.2218898550107684\n",
      "eval info: group_auc:0.647, mean_mrr:0.2992, ndcg@10:0.3959, ndcg@5:0.3292\n",
      "at epoch 3 , train time: 691.2 eval time: 154.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 3690 , total_loss: 1.1871, data_loss: 1.3355: : 3693it [11:33,  5.32it/s]\n",
      "663it [00:01, 432.85it/s]\n",
      "1143it [00:47, 23.93it/s]\n",
      "73152it [00:14, 5140.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 4\n",
      "train info: logloss loss:1.1870706619655993\n",
      "eval info: group_auc:0.6385, mean_mrr:0.2955, ndcg@10:0.3881, ndcg@5:0.323\n",
      "at epoch 4 , train time: 693.8 eval time: 156.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 3690 , total_loss: 1.1485, data_loss: 1.0954: : 3693it [11:29,  5.35it/s]\n",
      "663it [00:01, 425.09it/s]\n",
      "1143it [00:47, 23.85it/s]\n",
      "73152it [00:12, 5796.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 5\n",
      "train info: logloss loss:1.148466747255142\n",
      "eval info: group_auc:0.6353, mean_mrr:0.2976, ndcg@10:0.3895, ndcg@5:0.3249\n",
      "at epoch 5 , train time: 689.8 eval time: 154.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<recommenders.models.newsrec.models.nrms.NRMSModel at 0x7f0fc7942200>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d410d89d-8fc6-411c-a9e8-eaa7fc454d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "663it [00:01, 440.28it/s] \n",
      "1143it [00:48, 23.60it/s]\n",
      "73152it [00:12, 5802.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.6353, 'mean_mrr': 0.2976, 'ndcg@5': 0.3249, 'ndcg@10': 0.3895}\n"
     ]
    }
   ],
   "source": [
    "res_syn = model.run_eval(dev_news_file, dev_behaviors_file)\n",
    "print(res_syn)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe0e61ee-7634-4706-844b-ec2f2b0ec61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/notebook_utils.json+json": {
       "data": 0.6353,
       "encoder": "json",
       "name": "group_auc"
      }
     },
     "metadata": {
      "notebook_utils": {
       "data": true,
       "display": false,
       "name": "group_auc"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/notebook_utils.json+json": {
       "data": 0.2976,
       "encoder": "json",
       "name": "mean_mrr"
      }
     },
     "metadata": {
      "notebook_utils": {
       "data": true,
       "display": false,
       "name": "mean_mrr"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/notebook_utils.json+json": {
       "data": 0.3249,
       "encoder": "json",
       "name": "ndcg@5"
      }
     },
     "metadata": {
      "notebook_utils": {
       "data": true,
       "display": false,
       "name": "ndcg@5"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/notebook_utils.json+json": {
       "data": 0.3895,
       "encoder": "json",
       "name": "ndcg@10"
      }
     },
     "metadata": {
      "notebook_utils": {
       "data": true,
       "display": false,
       "name": "ndcg@10"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Record results for tests - ignore this cell\n",
    "store_metadata(\"group_auc\", res_syn['group_auc'])\n",
    "store_metadata(\"mean_mrr\", res_syn['mean_mrr'])\n",
    "store_metadata(\"ndcg@5\", res_syn['ndcg@5'])\n",
    "store_metadata(\"ndcg@10\", res_syn['ndcg@10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a310e45-b582-466e-92b4-dc4aa9c1bcd3",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a4ca68-4b8e-4709-8ffe-b9cae7c71c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(data_path, \"model\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model.model.save_weights(os.path.join(model_path, \"nrms_ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1f46d-1f22-436f-86eb-621a0fd23a39",
   "metadata": {},
   "source": [
    "## Output Prediction File\n",
    "This code segment is used to generate the prediction.zip file, which is in the same format in [MIND Competition Submission Tutorial](https://competitions.codalab.org/competitions/24122#learn_the_details-submission-guidelines).\n",
    "\n",
    "Please change the `MIND_type` parameter to `large` if you want to submit your prediction to [MIND Competition](https://msnews.github.io/competition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cccb15e2-c927-4c22-811e-3f33995326b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "663it [00:01, 345.14it/s]\n",
      "1143it [00:47, 24.30it/s]\n",
      "73152it [00:11, 6226.21it/s]\n"
     ]
    }
   ],
   "source": [
    "group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aecd1134-5b08-4118-9220-44eab1c68c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73152it [00:01, 55368.57it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f988a8c-5e8f-4962-bb5e-43a5b6ca3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f9ee5-146e-4c8b-97ad-59c885b46c4a",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://wuch15.github.io/paper/EMNLP2019-NRMS.pdf\n",
    "\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "793306ff-fe00-4fff-b7d3-776475b2fa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1:17:50\n"
     ]
    }
   ],
   "source": [
    "# Calculate elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Convert the elapsed time into hours, minutes, and seconds\n",
    "hours, remainder = divmod(elapsed_time, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "# Print the result in H:M:S format\n",
    "print(f\"Elapsed time: {int(hours)}:{int(minutes)}:{int(seconds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c1739-a12d-438b-b26e-07330ac38514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sb3)",
   "language": "python",
   "name": "sb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
